{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872744ae-a8b8-4796-9eff-ecbae30ae4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import openturns as ot\n",
    "# Display the final graph\n",
    "import openturns.viewer as viewer\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh as tr\n",
    "from importlib import reload\n",
    "from functools import partial\n",
    "\n",
    "from math import pi\n",
    "from joblib import Parallel, delayed\n",
    "from importlib import reload\n",
    "from IPython.display import display, clear_output\n",
    "from time import time\n",
    "from sympy.printing import latex\n",
    "from trimesh import viewer as trview\n",
    "import sklearn\n",
    "\n",
    "from scipy.optimize import OptimizeResult, minimize, basinhopping, \\\n",
    "                           differential_evolution, brute, shgo, check_grad, \\\n",
    "                           approx_fprime, fsolve, NonlinearConstraint, Bounds, approx_fprime\n",
    "\n",
    "import tqdm\n",
    "import otaf\n",
    "\n",
    "from gldpy import GLD\n",
    "\n",
    "ot.Log.Show(ot.Log.NONE)\n",
    "np.set_printoptions(suppress=True)\n",
    "ar = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817c72a-0818-4d16-a347-bc57ef3cf4d7",
   "metadata": {},
   "source": [
    "# Notebook for the analysis of a system comprised of N + 2 parts, 2 plates with N = N1 x N2 holes, and N pins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3fc3-09ea-4e9a-bca2-0a532e8398eb",
   "metadata": {},
   "source": [
    "### Defintion on global descriptive parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91253f14-bf22-495a-b2da-aa89d49d970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NX = 2 ## Number of holes on x axis\n",
    "NY = 2 ## Number of holes on y axis\n",
    "Dext = 20 ## Diameter of holes in mm\n",
    "Dint = 19.8 ## Diameter of pins in mm\n",
    "EH = 50 ## Distance between the hole axises\n",
    "LB = 25 # Distance between border holes axis and edge.\n",
    "hPlate = 30 #Height of the plates in mm\n",
    "hPin = 60 #Height of the pins in mm\n",
    "\n",
    "CIRCLE_RESOLUTION = 16 # NUmber of points to model the contour of the outer holes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa6a57-ff00-4438-9487-0304ddcf7cd9",
   "metadata": {},
   "source": [
    "### Defining and constructing the system data dictionary\n",
    "\n",
    "The plates have NX * NY + 1 surfaces. The lower left point has coordinate 0,0,0\n",
    "\n",
    "We only model the surfaces that are touching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9be0ccd7-a39e-4eef-83c8-ff9d759040bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARTS = NX * NY * 2\n",
    "LX = (NX - 1) * EH + 2*LB\n",
    "LY = (NY - 1) * EH + 2*LB\n",
    "\n",
    "contour_points = ar([[0,0,0],[LX,0,0],[LX,LY,0],[0,LY,0]])\n",
    "\n",
    "R0 = ar([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "x_, y_, z_ = R0[0], R0[1], R0[2]\n",
    "\n",
    "Frame1 = ar([z_,y_,-x_])\n",
    "Frame2 = ar([-z_,y_,x_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42692f0e-e845-4efa-9470-805dc0d65b3b",
   "metadata": {},
   "source": [
    "First we define the base part dictionaries for the upper and lower plate, without holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a1bb46-a7f6-4d9d-82f0-07ceccb9ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_data = {\n",
    "    \"PARTS\" : {\n",
    "        '0' : {\n",
    "            \"a\" : {\n",
    "                \"FRAME\": Frame1,\n",
    "                \"POINTS\": {'A0' : ar([0,0,0]),\n",
    "                           'A1' : ar([LX,0,0]),\n",
    "                           'A2' : ar([LX,LY,0]),\n",
    "                           'A3' : ar([0,LY,0]),\n",
    "                        },\n",
    "                \"TYPE\": \"plane\",\n",
    "                \"INTERACTIONS\": ['P1a'],\n",
    "                \"CONSTRAINTS_D\": [\"PERFECT\"],\n",
    "                \"CONSTRAINTS_G\": [\"SLIDING\"],            \n",
    "            }\n",
    "        },\n",
    "        '1' : {\n",
    "            \"a\" : {\n",
    "                \"FRAME\": Frame2,\n",
    "                \"POINTS\": {'A0' : ar([0,0,0]),\n",
    "                           'A1' : ar([LX,0,0]),\n",
    "                           'A2' : ar([LX,LY,0]),\n",
    "                           'A3' : ar([0,LY,0]),\n",
    "                        },\n",
    "                \"TYPE\": \"plane\",\n",
    "                \"INTERACTIONS\": ['P0a'],\n",
    "                \"CONSTRAINTS_D\": [\"PERFECT\"],\n",
    "                \"CONSTRAINTS_G\": [\"SLIDING\"],            \n",
    "            }\n",
    "        }  \n",
    "    },\n",
    "    \"LOOPS\": {\n",
    "        \"COMPATIBILITY\": {\n",
    "        },\n",
    "    },\n",
    "    \"GLOBAL_CONSTRAINTS\": \"3D\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e81a47-6214-4774-ab58-8d16bd43ac9b",
   "metadata": {},
   "source": [
    "Then we iterate over the pin dimensions NX and NY, and create the corresponding holes and pins. At the same time there is 1 loop per pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29491ebe-37b5-4879-a740-64db3434d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_gen = otaf.common.alphabet_generator()\n",
    "next(alpha_gen) # skipping 'a' as it has already been used above\n",
    "part_id = 2 # Start part index for pins\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        pcor = ar([LB+i*EH, LB+j*EH, 0]) # Point coordinate for hole / pins\n",
    "        slab = next(alpha_gen) # Surface label, same for each mating pin so its easeir to track\n",
    "        # Creating pin\n",
    "        system_data[\"PARTS\"][str(part_id)] = {}\n",
    "        system_data[\"PARTS\"][str(part_id)][slab] = {\n",
    "            \"FRAME\": Frame1, # Frame doesn't really matter, as long as x is aligned on the axis\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dint / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P0{slab}\", f\"P1{slab}\"], \n",
    "            \"SURFACE_DIRECTION\": \"centrifugal\",\n",
    "            \"CONSTRAINTS_D\": [\"PERFECT\"], # No defects on the pins\n",
    "            \"BLOCK_ROTATIONS_G\": 'x', # The pins do not rotate around their axis\n",
    "            \"BLOCK_TRANSLATIONS_G\": 'x', # The pins do not slide along their axis\n",
    "        }\n",
    "        # Adding hole to part 0\n",
    "        system_data[\"PARTS\"][\"0\"][slab] = {\n",
    "            \"FRAME\": Frame1,\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dext / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P{part_id}{slab}\"], \n",
    "            \"SURFACE_DIRECTION\": \"centripetal\",\n",
    "        }\n",
    "        # Adding hole to part 1\n",
    "        system_data[\"PARTS\"][\"1\"][slab] = {\n",
    "            \"FRAME\": Frame2,\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dext / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P{part_id}{slab}\"],\n",
    "            \"SURFACE_DIRECTION\": \"centripetal\",\n",
    "        }\n",
    "        # Construct Compatibility loop\n",
    "        loop_id = f\"L{part_id-1}\"\n",
    "        formater = lambda i,l : f\"P{i}{l}{l.upper()}0\" \n",
    "        system_data[\"LOOPS\"][\"COMPATIBILITY\"][loop_id] = f\"P0aA0 -> {formater(0,slab)} -> {formater(part_id,slab)} -> {formater(1,slab)} -> P1aA0\"\n",
    "        part_id += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293f981a-efe3-4b44-b9f3-b7a580cf3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDA = otaf.AssemblyDataProcessor(system_data)\n",
    "SDA.generate_expanded_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e26ae8-3e27-496d-ac65-9f4385d89105",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLH = otaf.CompatibilityLoopHandling(SDA)\n",
    "compatibility_expressions = CLH.get_compatibility_expression_from_FO_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87736588-7cec-4360-b748-2dfc7666461e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ILH = otaf.InterfaceLoopHandling(SDA, CLH, circle_resolution=CIRCLE_RESOLUTION)\n",
    "interface_constraints = ILH.get_interface_loop_expressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d2f4ba-f4bd-425a-ba0c-50cabc500272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [v_d_0, w_d_0, beta_d_0, gamma_d_0, v_d_2, w_d_2, beta_d_2, gamma_d_2, v_d_5, w_d_5, beta_d_5, gamma_d_5, v_d_7, w_d_7, beta_d_7, gamma_d_7, v_d_8, w_d_8, beta_d_8, gamma_d_8, v_d_10, w_d_10, beta_d_10, gamma_d_10, v_d_11, w_d_11, beta_d_11, gamma_d_11, v_d_13, w_d_13, beta_d_13, gamma_d_13]\n"
     ]
    }
   ],
   "source": [
    "SOCAM = otaf.SystemOfConstraintsAssemblyModel(\n",
    "    compatibility_expressions, interface_constraints\n",
    ")\n",
    "\n",
    "SOCAM.embedOptimizationVariable()\n",
    "\n",
    "print(len(SOCAM.deviation_symbols), SOCAM.deviation_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be834b-fc7d-4fc3-85eb-2d8768c446ed",
   "metadata": {},
   "source": [
    "## Construction of the stochastic model of the defects.\n",
    "\n",
    "These are the max variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31049a41-8b2a-49c0-8142-2819f94c51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.1 * np.sqrt(2)\n",
    "Cm = 1  # Process capability\n",
    "\n",
    "# Defining the uncertainties on the position and orientation uncertainties.spheres_from_point_cloud\n",
    "sigma_e_pos = tol / (6 * Cm)\n",
    "theta_max = tol / hPlate\n",
    "sigma_e_theta = (2 * theta_max) / (6 * Cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449f3658-2055-4cd6-a9bb-0ef7d520204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandDeviationVect = otaf.distribution.get_composed_normal_defect_distribution(\n",
    "    defect_names=SOCAM.deviation_symbols,\n",
    "    sigma_dict = {\"alpha\":sigma_e_theta, \n",
    "                  \"beta\":sigma_e_theta,\n",
    "                  \"gamma\":sigma_e_theta, \n",
    "                  \"u\":sigma_e_pos, \n",
    "                  \"v\":sigma_e_pos, \n",
    "                  \"w\":sigma_e_pos})\n",
    "NDim_Defects = len(SOCAM.deviation_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab91c6-d998-41d1-8739-502140b07ef4",
   "metadata": {},
   "source": [
    "## Estimating the bounds on the probability of failure of the model.\n",
    "\n",
    "### Global optimization basinhopping with GLD\n",
    "\n",
    "#### First we define the optimization functions $P_f(\\Theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83397ae2-05fb-4a58-af5f-3d66357fe8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to store results\n",
    "\n",
    "result_dict={}\n",
    "\n",
    "def store_results(x, fp_gld, fp_slack, gld_params, experiment_key=None, result_dict=result_dict):\n",
    "    x_key = otaf.common.bidirectional_string_to_array_conversion(x)\n",
    "    x_dict = {\"FP_GLD\": fp_gld, \"FP_SLACK\":fp_slack, \"GLD_PARAMS\": gld_params}\n",
    "    if experiment_key is None:\n",
    "        if x_key in result_dict.keys():\n",
    "            result_dict[x_key].update(x_dict)\n",
    "        else :\n",
    "            result_dict[x_key] = x_dict\n",
    "    else : \n",
    "        if experiment_key not in result_dict:\n",
    "            result_dict[experiment_key] = {}\n",
    "        if x_key in result_dict[experiment_key].keys():\n",
    "            result_dict[experiment_key][x_key].update(x_dict)\n",
    "        else:\n",
    "            result_dict[experiment_key][x_key] = x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b3fbdc-2bc3-4e79-a1b3-2dacfa491e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_MC_PF = 100000 #int(1e6) #1e4\n",
    "sample_gld = otaf.sampling.generate_and_transform_sequence(NDim_Defects, SIZE_MC_PF, RandDeviationVect) \n",
    "scale_factor = 1.0\n",
    "GLD_parameters = [] # We need the parameters of the generalized lambda distribution.\n",
    "\n",
    "result_list = [] # Will be list of lists, where each sub list is a list of the input vector x and one for the gld paramters\n",
    "\n",
    "# Generalized lambda distribution object for fitting\n",
    "gld = GLD('VSL')\n",
    "\n",
    "def model_base(x, sample=sample_gld):\n",
    "    \"x is the vector of standard deviations\"\n",
    "    # Model without surrogate, to get slack\n",
    "    x = sample * np.sqrt(x[np.newaxis, :])\n",
    "    optimization_variables = otaf.uncertainty.compute_gap_optimizations_on_sample_batch(\n",
    "        constraint_matrix_generator=SOCAM,\n",
    "        deviation_array=x,\n",
    "        batch_size=500,\n",
    "        n_cpu=-1,\n",
    "        progress_bar=True,\n",
    "        verbose=0,\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    slack_values = optimization_variables[:,-1]\n",
    "    return slack_values\n",
    "\n",
    "@otaf.optimization.scaling(scale_factor)\n",
    "def optimization_function_mini(x, failure_slack=0.0, model=model_base, experiment_key=None, result_dict=result_dict):\n",
    "    # Here we search the minimal probability of failure\n",
    "    slack = model(x)\n",
    "    gld_params = gld.fit_LMM(slack,  disp_fit=False, disp_optimizer=False)\n",
    "    fp_slack = np.where(slack<failure_slack,1,0).mean()\n",
    "    fp_gld = np.nan\n",
    "    if np.any(np.isnan(gld_params)):\n",
    "        fp_out = fp_slack\n",
    "    else :\n",
    "        #print(\"\\tgld_params:\", gld_params)\n",
    "        fp_gld = gld.CDF_num(failure_slack, gld_params)\n",
    "        fp_out = fp_gld\n",
    "    \n",
    "    store_results(x, fp_gld, fp_slack, gld_params, experiment_key, result_dict)\n",
    "    return fp_out\n",
    "\n",
    "\n",
    "@otaf.optimization.scaling(scale_factor)\n",
    "def optimization_function_maxi(x, failure_slack=0.0, model=model_base, experiment_key=None, result_dict=result_dict):\n",
    "    # Here we search the maximal probability of failure so negative output\n",
    "    slack = model(x)\n",
    "    gld_params = gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False)\n",
    "    fp_slack = np.where(slack<failure_slack,1,0).mean()\n",
    "    fp_gld = np.nan\n",
    "    if np.any(np.isnan(gld_params)):\n",
    "        fp_out = fp_slack\n",
    "    else :\n",
    "        #print(\"\\tgld_params:\", gld_params)\n",
    "        fp_gld = gld.CDF_num(failure_slack, gld_params)\n",
    "        fp_out = fp_gld\n",
    "    \n",
    "    store_results(x, fp_gld, fp_slack, gld_params, experiment_key, result_dict)\n",
    "\n",
    "    return fp_out*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805656b-91b6-4e12-bd5b-a8f2b984eea6",
   "metadata": {},
   "source": [
    "### Variance (std) based parameter constraint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c5ac89-cf9f-44bc-a7bb-7628704e4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "midof_funcs = otaf.tolerances.MiSdofToleranceZones()\n",
    "\n",
    "feature_constraint_list = []\n",
    "\n",
    "# We know that all features are cylindrical, with same values/dimensions\n",
    "for i in range(8):\n",
    "    fconst = otaf.tolerances.FeatureLevelStatisticalConstraint(\n",
    "        midof_funcs.cylindrical_zone,\n",
    "        mif_args = (tol, hPlate),\n",
    "        n_dof = 4,\n",
    "        n_sample = 80000,\n",
    "        target = \"std\", #\"prob\",\n",
    "        target_val = sigma_e_pos*np.sqrt(1-(2/np.pi)), #0.002699, #\n",
    "        isNormal = True,\n",
    "        normalizeOutput = True,\n",
    "    )\n",
    "    feature_constraint_list.append(fconst)\n",
    "\n",
    "# The input of this object would be a list of parameters (their real value)\n",
    "composed_assembly_constraint = otaf.tolerances.ComposedAssemblyLevelStatisticalConstraint(feature_constraint_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8c2424-bc79-4379-bc24-6ca62a8a1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds_one_feature = [[0.0,0.0], [0.0, sigma_e_pos], #u, mean std\n",
    "                            [0.0,0.0], [0.0, sigma_e_pos], #v, mean std\n",
    "                            [0.0,0.0], [0.0, sigma_e_theta], #alpha, mean std\n",
    "                            [0.0,0.0], [0.0, sigma_e_theta] # beta, mean std\n",
    "                           ]\n",
    "param_bounds = [param_bounds_one_feature] * 8 #We have 8 identical features\n",
    "\n",
    "# The input of this object is a list of normalized parameters (between 0 and 1)\n",
    "normalized_assembly_constraint = otaf.tolerances.NormalizedAssemblyLevelConstraint(\n",
    "    composed_assembly_constraint,\n",
    "    param_val_bounds=param_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836b5ec-5be9-4f70-a69a-4a8e88ea6714",
   "metadata": {},
   "source": [
    "#### The assembly constraint takes as an input the list of list of paramters for all the features. But as the distriutions (normals) are suppposed to be centered, we only need to have the standard deviations as inputs so we construct a little intermediary class that takes as an input only the standard deviations and not the means, and completes the means with 0 to pass it to the assembly constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb8e9f22-18a2-45b1-8385-bd611fc3b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_constraint_no_mean(x, scale_factor=1.0, result_dict=result_dict, experiment_key=None):\n",
    "    \"\"\" The functions takes directly the concatenated list of all normalized parameters, and reconstructs the right object.\n",
    "    There should be 32 variables for the standard deviations, we just add the mean values in the vector so the input is correct \n",
    "    for the constraint object\n",
    "    \"\"\"\n",
    "    assert len(param_list)==32, \"problem with input.\"\n",
    "    zer = np.zeros(4) # These are the mean values (all 0)\n",
    "    pl = np.array(param_list)\n",
    "    params_for_assembly = []\n",
    "    for i in range(8):\n",
    "        params = x[i*4:i*4+4]\n",
    "        pa = [item for pair in zip(zer, params) for item in pair]\n",
    "        params_for_assembly.append(pa)\n",
    "    constraint_array =  normalized_assembly_constraint(params_for_assembly)\n",
    "    \n",
    "    # Storing data\n",
    "    x_key = otaf.common.bidirectional_string_to_array_conversion(x)\n",
    "    data = {\"CONST\":constraint_array}\n",
    "    if experiment_key is not None:\n",
    "        if x_key in result_dict[experiment_key].keys():\n",
    "            result_dict[experiment_key][x_key].update(data)\n",
    "        else:\n",
    "            result_dict[experiment_key][x_key] = data\n",
    "    else :\n",
    "        if x_key in result_dict.keys():\n",
    "            result_dict[x_key].update(data)\n",
    "        else :\n",
    "            result_dict[x_key] = data\n",
    "\n",
    "    return constraint_array * scale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa290c-0362-4a63-83cb-d154d98b52f2",
   "metadata": {},
   "source": [
    "#### Now we create the assembly constraint for the optimization (so a non linear constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38aadcb-2449-4f63-848a-8e040c286905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nonlinear constraint with the updated vector-valued function and Jacobian\n",
    "nonLinearConstraint = lambda resDict, expKey : NonlinearConstraint(\n",
    "    fun = lambda x : assembly_constraint_no_mean(x, 1.0, resDict, expKey),\n",
    "    lb  = -0.005 * np.ones((8,)),\n",
    "    ub  = 0.005 * np.ones((8,)),\n",
    "    keep_feasible=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "900ac295-e74f-4fb0-9018-a25b96068f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pf_min_max_optimizer(failure_slack=0.0, result_dict=result_dict, experiment_key=None):\n",
    "    # Initial guess\n",
    "    x0 = [0.5] * NDim_Defects  # Initial guess\n",
    "    \n",
    "    # Perform the local optimization using COBYQA directly\n",
    "    res_maxi = minimize(\n",
    "        optimization_function_maxi, x0,\n",
    "        args=(failure_slack, model_base, experiment_key, result_dict),\n",
    "        method=\"COBYQA\", \n",
    "        jac=None, \n",
    "        bounds=Bounds(0.0, 1.0, keep_feasible=True),\n",
    "        constraints = nonLinearConstraint(result_dict, experiment_key),\n",
    "        options={\n",
    "            \"f_target\": -1.01, \n",
    "            \"maxiter\": 400,\n",
    "            \"maxfev\": 400,\n",
    "            \"feasibility_tol\": 1e-6,\n",
    "            \"initial_tr_radius\": np.sqrt(2*10),\n",
    "            \"final_tr_radius\": 1e-5,\n",
    "            \"disp\": False,\n",
    "            \"scale\": False\n",
    "        }\n",
    "    )\n",
    "    print('Maximization result:\\n', res_maxi)\n",
    "    \n",
    "    # Perform the local optimization using COBYQA directly\n",
    "    res_mini = minimize(\n",
    "        optimization_function_mini, x0, \n",
    "        args=(failure_slack, model2, experiment_key, result_dict),\n",
    "        method=\"COBYQA\", \n",
    "        jac=None, \n",
    "        bounds=Bounds(1e-16, 1.0, keep_feasible=True),\n",
    "        constraints = nonLinearConstraint(result_dict, experiment_key),\n",
    "        options={\n",
    "            \"f_target\": -0.01,\n",
    "            \"maxiter\": 400,\n",
    "            \"maxfev\": 400,\n",
    "            \"feasibility_tol\": 1e-6,\n",
    "            \"initial_tr_radius\": np.sqrt(2*10),\n",
    "            \"final_tr_radius\": 1e-5,\n",
    "            \"disp\": False,\n",
    "            \"scale\": False\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Minimization result:\\n\", res_mini)\n",
    "\n",
    "    # Get gld params and fp.\n",
    "    \n",
    "    s_x_min = otaf.common.bidirectional_string_to_array_conversion(res_mini.x)\n",
    "    s_x_max = otaf.common.bidirectional_string_to_array_conversion(res_maxi.x)\n",
    "    \n",
    "    if experiment_key :\n",
    "        gld_min = result_dict[experiment_key][s_x_min]['GLD_PARAMS']\n",
    "        gld_max = result_dict[experiment_key][s_x_max]['GLD_PARAMS']\n",
    "        fp_min = result_dict[experiment_key][s_x_min]['FP_GLD']\n",
    "        fp_max = result_dict[experiment_key][s_x_max]['FP_GLD']\n",
    "    else :\n",
    "        gld_min = result_dict[s_x_min]['GLD_PARAMS']\n",
    "        gld_max = result_dict[s_x_max]['GLD_PARAMS']\n",
    "        fp_min = result_dict[s_x_min]['FP_GLD']\n",
    "        fp_max = result_dict[s_x_max]['FP_GLD']\n",
    "\n",
    "    return (res_mini.x, res_maxi.x), (gld_min, gld_max), (fp_min, fp_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5109c28c-5eba-4150-b401-cd022e47e6c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res_x_000, res_gld_000, res_fp_000 \u001b[38;5;241m=\u001b[39m \u001b[43mpf_min_max_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiment_slack00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m res_x_005, res_gld_005, res_fp_005 \u001b[38;5;241m=\u001b[39m pf_min_max_optimizer(\u001b[38;5;241m0.05\u001b[39m, result_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_slack005\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m res_x_006, res_gld_006, res_fp_006 \u001b[38;5;241m=\u001b[39m pf_min_max_optimizer(\u001b[38;5;241m0.06\u001b[39m, result_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_slack010\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m, in \u001b[0;36mpf_min_max_optimizer\u001b[0;34m(failure_slack, result_dict, experiment_key)\u001b[0m\n\u001b[1;32m      3\u001b[0m x0 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.5\u001b[39m] \u001b[38;5;241m*\u001b[39m NDim_Defects  \u001b[38;5;66;03m# Initial guess\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform the local optimization using COBYQA directly\u001b[39;00m\n\u001b[1;32m      6\u001b[0m res_maxi \u001b[38;5;241m=\u001b[39m minimize(\n\u001b[1;32m      7\u001b[0m     optimization_function_maxi, x0,\n\u001b[0;32m----> 8\u001b[0m     args\u001b[38;5;241m=\u001b[39m(failure_slack, \u001b[43mmodel2\u001b[49m, experiment_key, result_dict),\n\u001b[1;32m      9\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOBYQA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     10\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     11\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mBounds(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, keep_feasible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     12\u001b[0m     constraints \u001b[38;5;241m=\u001b[39m nonLinearConstraint(result_dict, experiment_key),\n\u001b[1;32m     13\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf_target\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.01\u001b[39m, \n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxfev\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeasibility_tol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-6\u001b[39m,\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_tr_radius\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_tr_radius\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     }\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximization result:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, res_maxi)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Perform the local optimization using COBYQA directly\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "res_x_000, res_gld_000, res_fp_000 = pf_min_max_optimizer(0.0, result_dict, \"experiment_slack00\")\n",
    "res_x_005, res_gld_005, res_fp_005 = pf_min_max_optimizer(0.05, result_dict, \"experiment_slack005\")\n",
    "res_x_006, res_gld_006, res_fp_006 = pf_min_max_optimizer(0.06, result_dict, \"experiment_slack010\")\n",
    "res_x_001, res_gld_001, res_fp_001 = pf_min_max_optimizer(0.01, result_dict, \"experiment_slack001\")\n",
    "res_x_002, res_gld_002, res_fp_002 = pf_min_max_optimizer(0.02, result_dict, \"experiment_slack002\")\n",
    "res_x_003, res_gld_003, res_fp_003 = pf_min_max_optimizer(0.02, result_dict, \"experiment_slack003\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7611c87-c114-48b0-babe-9765b4a0c74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9df87-606e-49fd-b90d-33d1e92fc9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c34a41-0479-4d08-b8ed-44bbe17e4791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b32bf3-1f8a-4e76-8cf0-e8df3e45090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0eb93f-1a5a-456a-ad65-b86f0c100471",
   "metadata": {},
   "outputs": [],
   "source": [
    "otaf.plotting.plot_gld_pbox_cdf(gld,\n",
    "          [0.05388563, 0.01424974, 0.39190849, 0.12699835], \n",
    "          [0.04306886, 0.02397462, 0.36453265, 0.13973758],\n",
    "          np.linspace(-0.025, 0.085, 1000),\n",
    "          xlabel=\"s\", ylabel=r\"$P_f$\", title=\"P-Box of the Slack\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb5870-0875-4677-9efe-c2bee9e9f7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basinhopping for the maximization function using COBYQA\n",
    "x0_maxi = [0.25] * NDim_Defects  # Initial guess\n",
    "\n",
    "# Update minimizer_kwargs_maxi to use COBYQA\n",
    "minimizer_kwargs_maxi = {\n",
    "    \"method\": \"COBYQA\",   # Use COBYQA method\n",
    "    \"args\": (model_base,),     # Update args to match COBYQA requirements\n",
    "    \"constraints\": nonLinearConstraint,\n",
    "    \"bounds\": Bounds(lb=0.0,ub=1.0, keep_feasible=True),\n",
    "    \"options\": {\n",
    "        \"f_target\": -0.1, \n",
    "        \"maxiter\": 1000,\n",
    "        \"maxfev\": 4000,\n",
    "        \"feasibility_tol\": 1e-9, # tol on constraint violation\n",
    "        \"initial_tr_radius\": np.sqrt(2*32),\n",
    "        \"final_tr_radius\": 1e-4,\n",
    "        \"disp\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Running basinhopping with COBYQA as the local optimizer\n",
    "res_maxi = basinhopping(\n",
    "    optimization_function_maxi, x0_maxi,\n",
    "    niter=5,\n",
    "    T=1,\n",
    "    stepsize=3.0,\n",
    "    niter_success=19,\n",
    "    interval=5,\n",
    "    minimizer_kwargs=minimizer_kwargs_maxi,\n",
    "    disp=True,\n",
    "    #take_step=step_taking,\n",
    "    #accept_test=accept_test,\n",
    "    #callback=callback\n",
    ")\n",
    "\n",
    "print(\"Maximization Result with COBYQA:\")\n",
    "print(res_maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3c1a4-7d8f-441d-a59d-6be0897b7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_maxi.x.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687ab1e-cb51-4d88-8aac-39655110c711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fea5b5-191c-4ee7-be87-e7cc47a123f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = ot.Normal()\n",
    "func = ot.SymbolicFunction([\"x\"], [\"abs(x)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd7a4a-8080-492e-bcd3-f818072e212e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
