{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872744ae-a8b8-4796-9eff-ecbae30ae4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import openturns as ot\n",
    "# Display the final graph\n",
    "import openturns.viewer as viewer\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh as tr\n",
    "from importlib import reload\n",
    "from functools import partial\n",
    "\n",
    "from math import pi\n",
    "from joblib import Parallel, delayed\n",
    "from importlib import reload\n",
    "from IPython.display import display, clear_output\n",
    "from time import time\n",
    "from sympy.printing import latex\n",
    "from trimesh import viewer as trview\n",
    "import sklearn\n",
    "\n",
    "from scipy.optimize import OptimizeResult, minimize, basinhopping, differential_evolution, brute, shgo, check_grad, approx_fprime, fsolve, NonlinearConstraint, Bounds\n",
    "\n",
    "import tqdm\n",
    "import otaf\n",
    "\n",
    "from gldpy import GLD\n",
    "\n",
    "ot.Log.Show(ot.Log.NONE)\n",
    "np.set_printoptions(suppress=True)\n",
    "ar = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817c72a-0818-4d16-a347-bc57ef3cf4d7",
   "metadata": {},
   "source": [
    "# Notebook for the analysis of a system comprised of N + 2 parts, 2 plates with N = N1 x N2 holes, and N pins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3fc3-09ea-4e9a-bca2-0a532e8398eb",
   "metadata": {},
   "source": [
    "### Defintion on global descriptive parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91253f14-bf22-495a-b2da-aa89d49d970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NX = 2 ## Number of holes on x axis\n",
    "NY = 2 ## Number of holes on y axis\n",
    "Dext = 20 ## Diameter of holes in mm\n",
    "Dint = 19.8 ## Diameter of pins in mm\n",
    "EH = 50 ## Distance between the hole axises\n",
    "LB = 25 # Distance between border holes axis and edge.\n",
    "hPlate = 30 #Height of the plates in mm\n",
    "hPin = 60 #Height of the pins in mm\n",
    "\n",
    "CIRCLE_RESOLUTION = 16 # NUmber of points to model the contour of the outer holes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa6a57-ff00-4438-9487-0304ddcf7cd9",
   "metadata": {},
   "source": [
    "### Defining and constructing the system data dictionary\n",
    "\n",
    "The plates have NX * NY + 1 surfaces. The lower left point has coordinate 0,0,0\n",
    "\n",
    "We only model the surfaces that are touching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be0ccd7-a39e-4eef-83c8-ff9d759040bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARTS = NX * NY * 2\n",
    "LX = (NX - 1) * EH + 2*LB\n",
    "LY = (NY - 1) * EH + 2*LB\n",
    "\n",
    "contour_points = ar([[0,0,0],[LX,0,0],[LX,LY,0],[0,LY,0]])\n",
    "\n",
    "R0 = ar([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "x_, y_, z_ = R0[0], R0[1], R0[2]\n",
    "\n",
    "Frame1 = ar([z_,y_,-x_])\n",
    "Frame2 = ar([-z_,y_,x_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42692f0e-e845-4efa-9470-805dc0d65b3b",
   "metadata": {},
   "source": [
    "First we define the base part dictionaries for the upper and lower plate, without holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a1bb46-a7f6-4d9d-82f0-07ceccb9ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_data = {\n",
    "    \"PARTS\" : {\n",
    "        '0' : {\n",
    "            \"a\" : {\n",
    "                \"FRAME\": Frame1,\n",
    "                \"POINTS\": {'A0' : ar([0,0,0]),\n",
    "                           'A1' : ar([LX,0,0]),\n",
    "                           'A2' : ar([LX,LY,0]),\n",
    "                           'A3' : ar([0,LY,0]),\n",
    "                        },\n",
    "                \"TYPE\": \"plane\",\n",
    "                \"INTERACTIONS\": ['P1a'],\n",
    "                \"CONSTRAINTS_D\": [\"PERFECT\"],\n",
    "                \"CONSTRAINTS_G\": [\"SLIDING\"],            \n",
    "            }\n",
    "        },\n",
    "        '1' : {\n",
    "            \"a\" : {\n",
    "                \"FRAME\": Frame2,\n",
    "                \"POINTS\": {'A0' : ar([0,0,0]),\n",
    "                           'A1' : ar([LX,0,0]),\n",
    "                           'A2' : ar([LX,LY,0]),\n",
    "                           'A3' : ar([0,LY,0]),\n",
    "                        },\n",
    "                \"TYPE\": \"plane\",\n",
    "                \"INTERACTIONS\": ['P0a'],\n",
    "                \"CONSTRAINTS_D\": [\"PERFECT\"],\n",
    "                \"CONSTRAINTS_G\": [\"SLIDING\"],            \n",
    "            }\n",
    "        }  \n",
    "    },\n",
    "    \"LOOPS\": {\n",
    "        \"COMPATIBILITY\": {\n",
    "        },\n",
    "    },\n",
    "    \"GLOBAL_CONSTRAINTS\": \"3D\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e81a47-6214-4774-ab58-8d16bd43ac9b",
   "metadata": {},
   "source": [
    "Then we iterate over the pin dimensions NX and NY, and create the corresponding holes and pins. At the same time there is 1 loop per pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29491ebe-37b5-4879-a740-64db3434d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_gen = otaf.common.alphabet_generator()\n",
    "next(alpha_gen) # skipping 'a' as it has already been used above\n",
    "part_id = 2 # Start part index for pins\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        pcor = ar([LB+i*EH, LB+j*EH, 0]) # Point coordinate for hole / pins\n",
    "        slab = next(alpha_gen) # Surface label, same for each mating pin so its easeir to track\n",
    "        # Creating pin\n",
    "        system_data[\"PARTS\"][str(part_id)] = {}\n",
    "        system_data[\"PARTS\"][str(part_id)][slab] = {\n",
    "            \"FRAME\": Frame1, # Frame doesn't really matter, as long as x is aligned on the axis\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dint / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P0{slab}\", f\"P1{slab}\"], \n",
    "            \"SURFACE_DIRECTION\": \"centrifugal\",\n",
    "            \"CONSTRAINTS_D\": [\"PERFECT\"], # No defects on the pins\n",
    "            \"BLOCK_ROTATIONS_G\": 'x', # The pins do not rotate around their axis\n",
    "            \"BLOCK_TRANSLATIONS_G\": 'x', # The pins do not slide along their axis\n",
    "        }\n",
    "        # Adding hole to part 0\n",
    "        system_data[\"PARTS\"][\"0\"][slab] = {\n",
    "            \"FRAME\": Frame1,\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dext / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P{part_id}{slab}\"], \n",
    "            \"SURFACE_DIRECTION\": \"centripetal\",\n",
    "        }\n",
    "        # Adding hole to part 1\n",
    "        system_data[\"PARTS\"][\"1\"][slab] = {\n",
    "            \"FRAME\": Frame2,\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dext / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P{part_id}{slab}\"],\n",
    "            \"SURFACE_DIRECTION\": \"centripetal\",\n",
    "        }\n",
    "        # Construct Compatibility loop\n",
    "        loop_id = f\"L{part_id-1}\"\n",
    "        formater = lambda i,l : f\"P{i}{l}{l.upper()}0\" \n",
    "        system_data[\"LOOPS\"][\"COMPATIBILITY\"][loop_id] = f\"P0aA0 -> {formater(0,slab)} -> {formater(part_id,slab)} -> {formater(1,slab)} -> P1aA0\"\n",
    "        part_id += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293f981a-efe3-4b44-b9f3-b7a580cf3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDA = otaf.AssemblyDataProcessor(system_data)\n",
    "SDA.generate_expanded_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e26ae8-3e27-496d-ac65-9f4385d89105",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLH = otaf.CompatibilityLoopHandling(SDA)\n",
    "compatibility_expressions = CLH.get_compatibility_expression_from_FO_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87736588-7cec-4360-b748-2dfc7666461e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part 0, surface b for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'b', 'B0', '2', 'b', 'B0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'b', 'B1', '2', 'b', 'B1'], ['0', 'b', 'B2', '2', 'b', 'B2']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0bB0P2bB0 with GP0bB1P2bB1\n",
      "Matching used and unused gap matrices: GP0bB0P2bB0 with GP0bB2P2bB2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 0, surface c for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'c', 'C0', '3', 'c', 'C0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'c', 'C1', '3', 'c', 'C1'], ['0', 'c', 'C2', '3', 'c', 'C2']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0cC0P3cC0 with GP0cC1P3cC1\n",
      "Matching used and unused gap matrices: GP0cC0P3cC0 with GP0cC2P3cC2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 0, surface d for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'd', 'D0', '4', 'd', 'D0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'd', 'D1', '4', 'd', 'D1'], ['0', 'd', 'D2', '4', 'd', 'D2']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0dD0P4dD0 with GP0dD1P4dD1\n",
      "Matching used and unused gap matrices: GP0dD0P4dD0 with GP0dD2P4dD2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 0, surface e for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'e', 'E0', '5', 'e', 'E0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'e', 'E2', '5', 'e', 'E2'], ['0', 'e', 'E1', '5', 'e', 'E1']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0eE0P5eE0 with GP0eE2P5eE2\n",
      "Matching used and unused gap matrices: GP0eE0P5eE0 with GP0eE1P5eE1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 1, surface a for plane-to-plane interactions.\n",
      "usedGMatDat [['1', 'a', 'A0', '0', 'a', 'A0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['1', 'a', 'A3', '0', 'a', 'A3'], ['1', 'a', 'A1', '0', 'a', 'A1'], ['1', 'a', 'A2', '0', 'a', 'A2']]\n",
      "Found 3 unused gap matrices.\n",
      "Generated 3 interaction matrix loops for current matching.\n",
      "Processing part 2, surface b for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['2', 'b', 'B0', '1', 'b', 'B0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['2', 'b', 'B1', '1', 'b', 'B2'], ['2', 'b', 'B1', '0', 'b', 'B1'], ['2', 'b', 'B0', '0', 'b', 'B0'], ['2', 'b', 'B2', '1', 'b', 'B1'], ['2', 'b', 'B2', '0', 'b', 'B2']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP2bB0P1bB0 with GP2bB1P1bB2\n",
      "Matching used and unused gap matrices: GP2bB0P1bB0 with GP2bB2P1bB1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 3, surface c for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['3', 'c', 'C0', '1', 'c', 'C0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['3', 'c', 'C2', '0', 'c', 'C2'], ['3', 'c', 'C0', '0', 'c', 'C0'], ['3', 'c', 'C1', '0', 'c', 'C1'], ['3', 'c', 'C1', '1', 'c', 'C2'], ['3', 'c', 'C2', '1', 'c', 'C1']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP3cC0P1cC0 with GP3cC1P1cC2\n",
      "Matching used and unused gap matrices: GP3cC0P1cC0 with GP3cC2P1cC1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 4, surface d for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['4', 'd', 'D0', '1', 'd', 'D0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['4', 'd', 'D1', '1', 'd', 'D2'], ['4', 'd', 'D2', '0', 'd', 'D2'], ['4', 'd', 'D1', '0', 'd', 'D1'], ['4', 'd', 'D0', '0', 'd', 'D0'], ['4', 'd', 'D2', '1', 'd', 'D1']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP4dD0P1dD0 with GP4dD1P1dD2\n",
      "Matching used and unused gap matrices: GP4dD0P1dD0 with GP4dD2P1dD1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 5, surface e for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['5', 'e', 'E0', '1', 'e', 'E0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['5', 'e', 'E2', '0', 'e', 'E2'], ['5', 'e', 'E0', '0', 'e', 'E0'], ['5', 'e', 'E1', '1', 'e', 'E2'], ['5', 'e', 'E2', '1', 'e', 'E1'], ['5', 'e', 'E1', '0', 'e', 'E1']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP5eE0P1eE0 with GP5eE1P1eE2\n",
      "Matching used and unused gap matrices: GP5eE0P1eE0 with GP5eE2P1eE1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n"
     ]
    }
   ],
   "source": [
    "ILH = otaf.InterfaceLoopHandling(SDA, CLH, circle_resolution=CIRCLE_RESOLUTION)\n",
    "interface_constraints = ILH.get_interface_loop_expressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d2f4ba-f4bd-425a-ba0c-50cabc500272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [v_d_0, w_d_0, beta_d_0, gamma_d_0, v_d_2, w_d_2, beta_d_2, gamma_d_2, v_d_5, w_d_5, beta_d_5, gamma_d_5, v_d_7, w_d_7, beta_d_7, gamma_d_7, v_d_8, w_d_8, beta_d_8, gamma_d_8, v_d_10, w_d_10, beta_d_10, gamma_d_10, v_d_11, w_d_11, beta_d_11, gamma_d_11, v_d_13, w_d_13, beta_d_13, gamma_d_13]\n"
     ]
    }
   ],
   "source": [
    "SOCAM = otaf.SystemOfConstraintsAssemblyModel(\n",
    "    compatibility_expressions, interface_constraints\n",
    ")\n",
    "\n",
    "SOCAM.embedOptimizationVariable()\n",
    "\n",
    "print(len(SOCAM.deviation_symbols), SOCAM.deviation_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be834b-fc7d-4fc3-85eb-2d8768c446ed",
   "metadata": {},
   "source": [
    "## Construction of the stochastic model of the defects.\n",
    "\n",
    "These are the max variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31049a41-8b2a-49c0-8142-2819f94c51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.1 * np.sqrt(2)\n",
    "Cm = 1  # Process capability\n",
    "\n",
    "# Defining the uncertainties on the position and orientation uncertainties.\n",
    "sigma_e_pos = tol / (6 * Cm)\n",
    "theta_max = tol / hPlate\n",
    "sigma_e_theta = (2 * theta_max) / (6 * Cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449f3658-2055-4cd6-a9bb-0ef7d520204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandDeviationVect = otaf.distribution.get_composed_normal_defect_distribution(\n",
    "    defect_names=SOCAM.deviation_symbols,\n",
    "    sigma_dict = {\"alpha\":sigma_e_theta, \n",
    "                  \"beta\":sigma_e_theta,\n",
    "                  \"gamma\":sigma_e_theta, \n",
    "                  \"u\":sigma_e_pos, \n",
    "                  \"v\":sigma_e_pos, \n",
    "                  \"w\":sigma_e_pos})\n",
    "dim_devs = int(RandDeviationVect.getDimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a0a59-111e-461e-b796-afacf7adce72",
   "metadata": {},
   "source": [
    "## Estimating the bounds on the probability of failure of the model.\n",
    "\n",
    "- First by exploring the whle parameter space, by generating a LHS in the (normalized) parameter space and doing a double loop montecarlo\n",
    "- By using the parameter constraint function to guide an optimization algorithm to find the bounds on the probability of failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b207f-7a0c-4bdd-96d3-12d235ee3202",
   "metadata": {},
   "source": [
    "## Now lets first to a double loop monte-carlo to explore the full space of the parameters (using the intermediate lambda space) and the stochastic space, to be able to draw the full P-Box of the slack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60040ec1-5d78-428e-ba44-6b6adb01de5f",
   "metadata": {},
   "source": [
    "### Explicit constraint function on the 4 degrees of freedom of the cylindrical tolerance zone :\n",
    "\n",
    "$$λu2​+λv2​+λα2​+λβ2​+2(λu​λα​+λv​λβ​)−1=0$$\n",
    "\n",
    "This the constraint on the multipliers of the max standard deviation for each component of the DOFs. The defects are normal, centered and independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d99d7-56c6-4b9f-a4de-d28268b35398",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a94e1fe-9ae9-4000-96d5-1c1a896f28ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bounds = None\n",
    "SEED_MC_PF = 6436431\n",
    "SIZE_MC_PF = 20000 #int(1e6) #1e4\n",
    "s_values = np.zeros((N_lambda, SIZE_MC_PF)) # For each MC point we have a s value\n",
    "GLD_parameters = [] # We need the parameters of the generalized lambda distribution.\n",
    "failure_probabilities = []\n",
    "# Generalized lambda distribution object for fitting\n",
    "gld = GLD('VSL')\n",
    "\n",
    "start_time = time()  # Record the start time\n",
    "for i in range(N_lambda):\n",
    "    print(f\"Doing iteration {i} of {N_lambda}\")\n",
    "    if i>0:\n",
    "        fp = failure_probabilities\n",
    "        print(f\"Failure probability i-1 : {fp[i-1]}, Min: {min(fp)}, / Max: {max(fp)}\")\n",
    "        print(\"s_mean: \", s_values.mean().round(3), \"s_min: \", np.nanmin(s_values).round(3), \"s_max: \", np.nanmax(s_values).round(3))\n",
    "\n",
    "    ot.RandomGenerator.SetSeed(SEED_MC_PF)\n",
    "    deviation_samples = np.array(RandDeviationVect.getSample(SIZE_MC_PF)) * np.array(\n",
    "        lambda_sample_conditioned[i]\n",
    "    )\n",
    "    optimizations = otaf.uncertainty.compute_gap_optimizations_on_sample(\n",
    "            SOCAM,\n",
    "            deviation_samples,\n",
    "            bounds=bounds,\n",
    "            n_cpu=-1,\n",
    "            progress_bar=True,\n",
    "        )\n",
    "    \n",
    "    slack = np.array([opt.fun for opt in optimizations], dtype=float)*-1 #Normally there aren\"t any nans.\n",
    "    s_values[i,:] = slack\n",
    "    GLD_parameters.append(gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False))\n",
    "    failure_probabilities.append(gld.CDF_num(0, GLD_parameters[i]))\n",
    "\n",
    "\n",
    "print(f\"Done {len (lambda_sample_conditioned)} experiments.\")\n",
    "print(f\"Elapsed time: {time() - start_time:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d7e37-a5a0-4371-983b-aad3fb8ba30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = otaf.sampling.find_best_worst_quantile(np.array(lambda_sample_conditioned), np.array(failure_probabilities), 0.1)\n",
    "(best_5p_lambda, best_5p_res), (worst_5p_lambda, worst_5p_res) = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef201d9-f0c7-4d9a-8431-da3f26fab7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [ot.UserDefined(ot.Sample(s[:,np.newaxis])) for s in s_values]\n",
    "x_min, x_max = -0.03, 0.11\n",
    "sup_data, inf_data = otaf.distribution.compute_sup_inf_distributions(distributions, x_min, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d09b7e-a700-4d30-9e13-4d7cd8c71c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize colors and legends for each lambda sample\n",
    "colors = [[\"grey\"]] * lambda_sample_conditioned.getSize()\n",
    "legends = [\"\"] * lambda_sample_conditioned.getSize()\n",
    "\n",
    "# Plot the combined CDF with additional curves for the envelopes\n",
    "graph_full = otaf.plotting.plot_combined_CDF(distributions, x_min, x_max, colors, legends)\n",
    "graph_full = otaf.plotting.set_graph_legends(\n",
    "    graph_full,\n",
    "    x_title=\"j\",\n",
    "    y_title=\"P\",\n",
    "    title=\"Slack P-BOX 32 dimensions\",\n",
    "    legends=legends\n",
    ")\n",
    "\n",
    "# Add the upper and lower envelopes to the graph\n",
    "graph_full.add(ot.Curve(inf_data, \"blue\", \"solid\", 1.5, \"lower envelope\"))\n",
    "graph_full.add(ot.Curve(sup_data, \"red\", \"solid\", 1.5, \"upper envelope\"))\n",
    "view = viewer.View(graph_full, pixelsize=(1100, 750))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9ac3f-503d-4d98-804a-507201a7e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(failure_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175ab42-9b8b-4e48-abd4-55fb64a25d79",
   "metadata": {},
   "source": [
    "# Now we'll use the other lambda modelization, a bit more difficutl to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc29a0a-6b65-47e8-9c0d-6ce3ca604abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_limit_sample = otaf.sampling.generate_imprecise_probabilistic_samples([4]*8, -1, discretization=1)\n",
    "lambda_limit_sample_sub_choice = [next(lambda_limit_sample) for _ in range(60000)]\n",
    "lambda_limit_sample_sub_choice = np.stack(lambda_limit_sample_sub_choice)\n",
    "print(lambda_limit_sample_sub_choice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a0477-968f-4b75-8450-316b000245cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_lambda_beta(lambda_u, lambda_v, lambda_alpha):\n",
    "    \"\"\"\n",
    "    Solve the equation for lambda_beta given lambda_u, lambda_v, and lambda_alpha.\n",
    "    \"\"\"\n",
    "    def equation(lambda_beta):\n",
    "        return (lambda_u**2 + lambda_v**2 + lambda_alpha**2 + lambda_beta**2 +\n",
    "                2 * (lambda_u * lambda_alpha + lambda_v * lambda_beta) - 1)\n",
    "    \n",
    "    # Use a root-finding method to solve for lambda_beta\n",
    "    lambda_beta_initial_guess = 0.5\n",
    "    lambda_beta_solution = fsolve(equation, lambda_beta_initial_guess)[0]\n",
    "    \n",
    "    return lambda_beta_solution\n",
    "\n",
    "def generate_points_on_surface(num_points=1000):\n",
    "    \"\"\"\n",
    "    Generate points on the surface by solving for lambda_beta\n",
    "    given random values for lambda_u, lambda_v, and lambda_alpha.\n",
    "    \n",
    "    Returns:\n",
    "    - A numpy array of shape (num_valid_points, 4) where each row is \n",
    "      (lambda_u, lambda_v, lambda_alpha, lambda_beta).\n",
    "    \"\"\"\n",
    "    # Generate random values for lambda_u, lambda_v, lambda_alpha in [0, 1]\n",
    "    lambda_u = np.random.rand(num_points)\n",
    "    lambda_v = np.random.rand(num_points)\n",
    "    lambda_alpha = np.random.rand(num_points)\n",
    "    \n",
    "    # Assume lambda_beta = 0 and check if the inequality is satisfied\n",
    "    inequality_values = lambda_u**2 + lambda_v**2 + lambda_alpha**2 + 2 * (lambda_u * lambda_alpha)\n",
    "\n",
    "    # Filter valid points where inequality holds\n",
    "    valid_mask = inequality_values <= 1\n",
    "    lambda_u_valid = lambda_u[valid_mask]\n",
    "    lambda_v_valid = lambda_v[valid_mask]\n",
    "    lambda_alpha_valid = lambda_alpha[valid_mask]\n",
    "    \n",
    "    # Solve for lambda_beta for valid points\n",
    "    lambda_beta_valid = np.array([solve_for_lambda_beta(u, v, a) \n",
    "                                  for u, v, a in zip(lambda_u_valid, lambda_v_valid, lambda_alpha_valid)])\n",
    "\n",
    "    # Only keep points where the solved lambda_beta is between 0 and 1\n",
    "    final_mask = (lambda_beta_valid >= 0) & (lambda_beta_valid <= 1)\n",
    "    final_points = np.vstack((lambda_u_valid[final_mask],\n",
    "                              lambda_v_valid[final_mask],\n",
    "                              lambda_alpha_valid[final_mask],\n",
    "                              lambda_beta_valid[final_mask])).T\n",
    "    \n",
    "    return final_points\n",
    "\n",
    "# Generate the points on the surface\n",
    "points = generate_points_on_surface(num_points=20000)\n",
    "\n",
    "# Call the pair_plot function (assuming it's already defined)\n",
    "labels = ['lambda_u', 'lambda_v', 'lambda_alpha', 'lambda_beta']\n",
    "#otaf.plotting.pair_plot(points, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec9b31-167f-41ab-a3d2-38000577a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lambda_sample = [points[np.random.choice(points.shape[0], 200, replace=False)] for _ in range(8)]\n",
    "random_lambda_sample = np.hstack(random_lambda_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a858d-1a85-48cd-841e-205c10da8e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_lambda = random_lambda_sample.shape[0]\n",
    "bounds = None\n",
    "SEED_MC_PF = 6436431\n",
    "SIZE_MC_PF = 10000 #int(1e6) #1e4\n",
    "s_values = np.zeros((N_lambda, SIZE_MC_PF)) # For each MC point we have a s value\n",
    "GLD_parameters = [] # We need the parameters of the generalized lambda distribution.\n",
    "failure_probabilities = []\n",
    "# Generalized lambda distribution object for fitting\n",
    "gld = GLD('VSL')\n",
    "\n",
    "start_time = time()  # Record the start time\n",
    "for i in range(N_lambda):\n",
    "    print(f\"Doing iteration {i} of {N_lambda}\")\n",
    "    if i>0:\n",
    "        fp = failure_probabilities\n",
    "        print(f\"Failure probability i-1 : {fp[i-1]}, Min: {min(fp)}, / Max: {max(fp)}\")\n",
    "        print(\"s_mean: \", s_values.mean().round(3), \"s_min: \", np.nanmin(s_values).round(3), \"s_max: \", np.nanmax(s_values).round(3))\n",
    "\n",
    "    ot.RandomGenerator.SetSeed(SEED_MC_PF)\n",
    "    deviation_samples = np.array(RandDeviationVect.getSample(SIZE_MC_PF)) * random_lambda_sample[i]\n",
    "    optimizations = otaf.uncertainty.compute_gap_optimizations_on_sample(\n",
    "            SOCAM,\n",
    "            deviation_samples,\n",
    "            bounds=bounds,\n",
    "            n_cpu=-1,\n",
    "            progress_bar=True,\n",
    "        )\n",
    "    \n",
    "    slack = np.array([opt.fun for opt in optimizations], dtype=float)*-1 #Normally there aren\"t any nans.\n",
    "    s_values[i,:] = slack\n",
    "    GLD_parameters.append(gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False))\n",
    "    failure_probabilities.append(gld.CDF_num(0, GLD_parameters[i]))\n",
    "\n",
    "\n",
    "print(f\"Done {N_lambda} experiments.\")\n",
    "print(f\"Elapsed time: {time() - start_time:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba797e-b00f-4523-8476-b97e5b4c132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = otaf.sampling.find_best_worst_quantile(np.array(lambda_sample_conditioned), np.array(failure_probabilities), 0.1)\n",
    "(best_5p_lambda, best_5p_res), (worst_5p_lambda, worst_5p_res) = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d1b15-9131-4741-a4cb-b4217637c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [ot.UserDefined(ot.Sample(s[:,np.newaxis])) for s in s_values]\n",
    "x_min, x_max = -0.03, 0.11\n",
    "sup_data, inf_data = otaf.distribution.compute_sup_inf_distributions(distributions, x_min, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527d338-2d2b-43c0-9e76-8e03c57d6240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f384b-26ca-4aa0-8ec1-1471f2884d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize colors and legends for each lambda sample\n",
    "colors = [[\"grey\"]] * N_lambda\n",
    "legends = [\"\"] * N_lambda\n",
    "\n",
    "# Plot the combined CDF with additional curves for the envelopes\n",
    "graph_full = otaf.plotting.plot_combined_CDF(distributions, x_min, x_max, colors, legends)\n",
    "graph_full = otaf.plotting.set_graph_legends(\n",
    "    graph_full,\n",
    "    x_title=\"slack\",\n",
    "    y_title=\"$P_{slack}$\",\n",
    "    title=\"Slack P-BOX 32 dimensions\",\n",
    "    legends=legends\n",
    ")\n",
    "\n",
    "# Add the upper and lower envelopes to the graph\n",
    "graph_full.add(ot.Curve(inf_data, \"blue\", \"solid\", 1.5, \"lower envelope\"))\n",
    "graph_full.add(ot.Curve(sup_data, \"red\", \"solid\", 1.5, \"upper envelope\"))\n",
    "view = viewer.View(graph_full, pixelsize=(1100, 750))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9723baf-f91d-4ce9-ad5b-7fcfd88c1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "fig = plt.figure(dpi=150)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(sup_data[:, 0], sup_data[:, 1], color=\"tab:orange\", label=\"upper envelope\")\n",
    "ax.plot(inf_data[:, 0], inf_data[:, 1], color=\"tab:blue\", label=\"lower envelope\")\n",
    "ax.grid(True)\n",
    "ax.fill_between(\n",
    "    inf_data[:, 0], inf_data[:, 1], sup_data[:, 1], color=\"gray\", alpha=0.3\n",
    ")\n",
    "ax.set_xlabel(\"slack\")\n",
    "ax.set_ylabel(\"$P_{slack}$\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Slack P-Box 3D Assembly 32D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176e60a-1b48-467c-bbd8-a654452c511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum failure probability: {np.min(failure_probabilities):.5e}, Maximum failure probability: {np.max(failure_probabilities):.5e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f9521-d4fd-483e-a4da-bb5617225b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab91c6-d998-41d1-8739-502140b07ef4",
   "metadata": {},
   "source": [
    "## Global optimization basinhopping with GLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b659ba-59be-4385-a1a4-d2b2aebc6f5f",
   "metadata": {},
   "source": [
    "### First we define the optimization functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3fbdc-2bc3-4e79-a1b3-2dacfa491e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_MC_PF = 10000 #int(1e6) #1e4\n",
    "sample_gld = np.array(RandDeviationVect.getSample(SIZE_MC_PF))\n",
    "scale_factor = 1.0\n",
    "GLD_parameters = [] # We need the parameters of the generalized lambda distribution.\n",
    "\n",
    "# Generalized lambda distribution object for fitting\n",
    "gld = GLD('VSL')\n",
    "\n",
    "def model_base(x, sample=sample_gld):\n",
    "    # Model without surrogate, to get slack\n",
    "    x = sample * np.sqrt(x[np.newaxis, :])\n",
    "    optimization_variables = otaf.uncertainty.compute_gap_optimizations_on_sample_batch(\n",
    "        constraint_matrix_generator=SOCAM,\n",
    "        deviation_array=x,\n",
    "        batch_size=500,\n",
    "        n_cpu=-1,\n",
    "        progress_bar=True,\n",
    "        verbose=0,\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    slack_values = optimization_variables[:,-1]\n",
    "    return slack_values\n",
    "\n",
    "@otaf.optimization.scaling(scale_factor)\n",
    "def optimization_function_mini(x, model=model_base):\n",
    "    # Here we search the minimal probability of failure\n",
    "    slack = model(x)\n",
    "    gld_params = gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False)\n",
    "    if np.any(np.isnan(gld_params)):\n",
    "        failure_probability = np.where(slack<0,1,0).mean()\n",
    "    else :\n",
    "        print(\"gld_params:\", gld_params)\n",
    "        failure_probability = gld.CDF_num(0, gld_params)\n",
    "    return failure_probability\n",
    "\n",
    "@otaf.optimization.scaling(scale_factor)\n",
    "def optimization_function_maxi(x, model=model_base):\n",
    "    # Here we search the maximal probability of failure so negative output\n",
    "    slack = model(x)\n",
    "    gld_params = gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False)\n",
    "    if np.any(np.isnan(gld_params)):\n",
    "        failure_probability = np.where(slack<0,1,0).mean()\n",
    "    else :\n",
    "        print(\"gld_params:\", gld_params)\n",
    "        failure_probability = gld.CDF_num(0, gld_params)\n",
    "    return failure_probability*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4216b-dcef-4762-9bb1-613b46c5f111",
   "metadata": {},
   "source": [
    "### Explicit parameter feature constraints (not ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f63ca8-0615-4769-bdb3-1ca1c71470d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cylinder_feature_constraint(la):\n",
    "    \"\"\"Evaluates the cylinder constraint for a given lambda array.\"\"\"\n",
    "    sum_squares = np.dot(la, la)  # Equivalent to la[0]**2 + la[1]**2 + la[2]**2 + la[3]**2\n",
    "    cross_terms = 2 * (la[0] * la[2] + la[1] * la[3])\n",
    "    return sum_squares + cross_terms - 1\n",
    "\n",
    "def cylinder_feature_constraint_jacobian(la):\n",
    "    \"\"\"Computes the analytical Jacobian of the cylinder feature constraint.\"\"\"\n",
    "    u, v, alpha, beta = la\n",
    "    return np.array([\n",
    "        2 * u + 2 * alpha,  # df/du\n",
    "        2 * v + 2 * beta,   # df/dv\n",
    "        2 * alpha + 2 * u,  # df/dalpha\n",
    "        2 * beta + 2 * v    # df/dbeta\n",
    "    ])\n",
    "\n",
    "def assembly_feature_constraint(la8):\n",
    "    \"\"\"Applies the cylinder constraint to each 4-element slice of the lambda array, returning a vector of constraints.\"\"\"\n",
    "    return np.array([cylinder_feature_constraint(la8[i : i + 4]) for i in range(0, len(la8), 4)])\n",
    "\n",
    "def assembly_feature_constraint_jacobian(la8):\n",
    "    \"\"\"Constructs the Jacobian matrix for the vector of constraints, with each row representing the Jacobian of one cylinder constraint.\"\"\"\n",
    "    # Initialize a list to hold each constraint's Jacobian as a row in the matrix\n",
    "    jacobian = []\n",
    "    # Compute Jacobian for each 4-element segment in the lambda array\n",
    "    for i in range(0, len(la8), 4):\n",
    "        row_jacobian = np.zeros(len(la8))  # Create a zeroed row of the appropriate length\n",
    "        row_jacobian[i:i+4] = cylinder_feature_constraint_jacobian(la8[i:i+4])\n",
    "        jacobian.append(row_jacobian)\n",
    "    return np.array(jacobian)\n",
    "\n",
    "\n",
    "def cylinder_feature_constraint_hessian(la):\n",
    "    \"\"\"Computes the Hessian of the cylinder constraint for a given 4-element lambda array.\"\"\"\n",
    "    # Extract variables for readability\n",
    "    u, v, alpha, beta = la\n",
    "    # The Hessian matrix is symmetric, so we only need to define the unique elements\n",
    "    hessian = np.array([\n",
    "        [2, 0, 2, 0],  # d^2f/du^2, d^2f/du dv, d^2f/du dalpha, d^2f/du dbeta\n",
    "        [0, 2, 0, 2],  # d^2f/dv du, d^2f/dv^2, d^2f/dv dalpha, d^2f/dv dbeta\n",
    "        [2, 0, 2, 0],  # d^2f/dalpha du, d^2f/dalpha dv, d^2f/dalpha^2, d^2f/dalpha dbeta\n",
    "        [0, 2, 0, 2]   # d^2f/dbeta du, d^2f/dbeta dv, d^2f/dbeta dalpha, d^2f/dbeta^2\n",
    "    ])\n",
    "    return hessian\n",
    "\n",
    "def assembly_feature_constraint_hessian(la8):\n",
    "    \"\"\"Constructs the full Hessian matrix for the vector of constraints in the assembly.\"\"\"\n",
    "    n_constraints = len(la8) // 4\n",
    "    hessian_blocks = []\n",
    "    \n",
    "    # Build the Hessian by iterating over each 4-element segment\n",
    "    for i in range(n_constraints):\n",
    "        block_hessian = cylinder_feature_constraint_hessian(la8[i*4:i*4+4])\n",
    "        # Place the block into the full Hessian matrix for the constraint function\n",
    "        block_hessian_expanded = np.zeros((len(la8), len(la8)))\n",
    "        block_hessian_expanded[i*4:i*4+4, i*4:i*4+4] = block_hessian\n",
    "        hessian_blocks.append(block_hessian_expanded)\n",
    "    \n",
    "    # Sum the block Hessians to form the full Hessian matrix\n",
    "    full_hessian = np.sum(hessian_blocks, axis=0)\n",
    "    return full_hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805656b-91b6-4e12-bd5b-a8f2b984eea6",
   "metadata": {},
   "source": [
    "### Implicit parameter constrants (new version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5ac89-cf9f-44bc-a7bb-7628704e4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "midof_funcs = otaf.tolerances.MiSdofToleranceZones()\n",
    "\n",
    "feature_constraint_list = []\n",
    "\n",
    "# We know that all features are cylindrical, with same values/dimensions\n",
    "for i in range(8):\n",
    "    fconst = otaf.tolerances.FeatureLevelStatisticalConstraint(\n",
    "        midof_funcs.cylindrical_zone,\n",
    "        mif_args = (tol, hPlate),\n",
    "        n_dof = 4,\n",
    "        n_sample = 100000,\n",
    "        target = \"std\", #\"prob\",\n",
    "        target_val = sigma_e_pos*np.sqrt(1-(2/np.pi)), #0.002699, #\n",
    "        isNormal = True,\n",
    "        normalizeOutput = True,\n",
    "    )\n",
    "    feature_constraint_list.append(fconst)\n",
    "\n",
    "composed_assembly_constraint = otaf.tolerances.ComposedAssemblyLevelStatisticalConstraint(feature_constraint_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c2424-bc79-4379-bc24-6ca62a8a1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds_one_feature = [[0.0,0.0], [1e-8, sigma_e_pos], #u, mean std\n",
    "                            [0.0,0.0], [1e-8, sigma_e_pos], #v, mean std\n",
    "                            [0.0,0.0], [1e-8, sigma_e_theta], #alpha, mean std\n",
    "                            [0.0,0.0], [1e-8, sigma_e_theta] # beta, mean std\n",
    "                           ]\n",
    "param_bounds = [param_bounds_one_feature] * 8 #We have 8 identical features\n",
    "\n",
    "normalized_assembly_constraint = otaf.tolerances.NormalizedAssemblyLevelConstraint(\n",
    "    composed_assembly_constraint,\n",
    "    param_val_bounds=param_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836b5ec-5be9-4f70-a69a-4a8e88ea6714",
   "metadata": {},
   "source": [
    "#### The assembly constraint takes as an input the list of list of paramters for all the features. But as the distriutions (normals) are suppposed to be centered, we only need to have the standard deviations as inputs so we construct a little intermediary class that takes as an input only the standard deviations and not the means, and completes the means with 0 to pass it to the assembly constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e9f22-18a2-45b1-8385-bd611fc3b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_constraint_no_mean(param_list, scale_out=True):\n",
    "    \"\"\" The functions takes directly the concatenated list of all parameters, and reconstructs the right object.\n",
    "    There should be 32 variables\n",
    "    \"\"\"\n",
    "    assert len(param_list)==32, \"problem with input.\"\n",
    "    zer = np.zeros(4)\n",
    "    pl = np.array(param_list)\n",
    "    params_for_assembly = []\n",
    "    for i in range(8):\n",
    "        params = param_list[i*4:i*4+4]\n",
    "        pa = [item for pair in zip(zer, params) for item in pair]\n",
    "        params_for_assembly.append(pa)\n",
    "    res =  normalized_assembly_constraint(params_for_assembly)\n",
    "    if scale_out :\n",
    "        return res * 10\n",
    "    else :\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f288747-0f05-47f2-bab5-7e805d549d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembly_constraint_no_mean([1.0,0.0,0.0,0]*8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa290c-0362-4a63-83cb-d154d98b52f2",
   "metadata": {},
   "source": [
    "#### Now we create the assembly constraint for the optimization (so a non linear constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38aadcb-2449-4f63-848a-8e040c286905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nonlinear constraint with the updated vector-valued function and Jacobian\n",
    "nonLinearConstraint = NonlinearConstraint(\n",
    "    fun=assembly_constraint_no_mean,\n",
    "    lb = -0.05 * np.ones((8,)),\n",
    "    ub = 0.05 * np.ones((8,)),\n",
    "    jac = \"2-point\",\n",
    "    #hess=assembly_feature_constraint_hessian\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb5870-0875-4677-9efe-c2bee9e9f7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basinhopping for the maximization function using COBYQA\n",
    "x0_maxi = [0.25] * RandDeviationVect.getDimension()  # Initial guess\n",
    "\n",
    "# Update minimizer_kwargs_maxi to use COBYQA\n",
    "minimizer_kwargs_maxi = {\n",
    "    \"method\": \"COBYQA\",   # Use COBYQA method\n",
    "    \"jac\": False,         # COBYQA doesn't use Jacobians\n",
    "    \"args\": (model_base,),     # Update args to match COBYQA requirements\n",
    "    \"constraints\": nonLinearConstraint,\n",
    "    \"bounds\": Bounds(lb=0.0,ub=1.0),\n",
    "    \"options\": {\n",
    "        \"f_target\": -0.2, \n",
    "        \"maxiter\": 1000,\n",
    "        \"maxfev\": 4000,\n",
    "        \"feasibility_tol\": 1e-2,\n",
    "        \"initial_tr_radius\": np.sqrt(32)*0.5,\n",
    "        \"final_tr_radius\": 0.33,\n",
    "        \"disp\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Running basinhopping with COBYQA as the local optimizer\n",
    "res_maxi = basinhopping(\n",
    "    optimization_function_maxi, x0_maxi,\n",
    "    niter=5,\n",
    "    T=1,\n",
    "    stepsize=3.0,\n",
    "    niter_success=19,\n",
    "    interval=5,\n",
    "    minimizer_kwargs=minimizer_kwargs_maxi,\n",
    "    disp=True,\n",
    "    #take_step=step_taking,\n",
    "    #accept_test=accept_test,\n",
    "    #callback=callback\n",
    ")\n",
    "\n",
    "print(\"Maximization Result with COBYQA:\")\n",
    "print(res_maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3c1a4-7d8f-441d-a59d-6be0897b7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_maxi.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b8b05-65b6-426c-b60d-bf23b5b19b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_function_maxi(np.array([0,0,1,0]*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687ab1e-cb51-4d88-8aac-39655110c711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fea5b5-191c-4ee7-be87-e7cc47a123f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = ot.Normal()\n",
    "func = ot.SymbolicFunction([\"x\"], [\"abs(x)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd7a4a-8080-492e-bcd3-f818072e212e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
