{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872744ae-a8b8-4796-9eff-ecbae30ae4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import openturns as ot\n",
    "# Display the final graph\n",
    "import openturns.viewer as viewer\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh as tr\n",
    "from importlib import reload\n",
    "from functools import partial\n",
    "\n",
    "from math import pi\n",
    "from joblib import Parallel, delayed\n",
    "from importlib import reload\n",
    "from IPython.display import display, clear_output\n",
    "from time import time\n",
    "from sympy.printing import latex\n",
    "from trimesh import viewer as trview\n",
    "import sklearn\n",
    "\n",
    "from scipy.optimize import OptimizeResult, minimize, basinhopping, \\\n",
    "                           differential_evolution, brute, shgo, check_grad, \\\n",
    "                           approx_fprime, fsolve, NonlinearConstraint, Bounds, approx_fprime\n",
    "\n",
    "import tqdm\n",
    "import otaf\n",
    "\n",
    "from gldpy import GLD\n",
    "\n",
    "ot.Log.Show(ot.Log.NONE)\n",
    "np.set_printoptions(suppress=True)\n",
    "ar = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4817c72a-0818-4d16-a347-bc57ef3cf4d7",
   "metadata": {},
   "source": [
    "# Notebook for the analysis of a system comprised of N + 2 parts, 2 plates with N = N1 x N2 holes, and N pins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3fc3-09ea-4e9a-bca2-0a532e8398eb",
   "metadata": {},
   "source": [
    "### Defintion on global descriptive parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91253f14-bf22-495a-b2da-aa89d49d970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NX = 2 ## Number of holes on x axis\n",
    "NY = 2 ## Number of holes on y axis\n",
    "Dext = 20 ## Diameter of holes in mm\n",
    "Dint = 19.8 ## Diameter of pins in mm\n",
    "EH = 50 ## Distance between the hole axises\n",
    "LB = 25 # Distance between border holes axis and edge.\n",
    "hPlate = 30 #Height of the plates in mm\n",
    "hPin = 60 #Height of the pins in mm\n",
    "\n",
    "CIRCLE_RESOLUTION = 16 # NUmber of points to model the contour of the outer holes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa6a57-ff00-4438-9487-0304ddcf7cd9",
   "metadata": {},
   "source": [
    "### Defining and constructing the system data dictionary\n",
    "\n",
    "The plates have NX * NY + 1 surfaces. The lower left point has coordinate 0,0,0\n",
    "\n",
    "We only model the surfaces that are touching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be0ccd7-a39e-4eef-83c8-ff9d759040bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARTS = NX * NY * 2\n",
    "LX = (NX - 1) * EH + 2*LB\n",
    "LY = (NY - 1) * EH + 2*LB\n",
    "\n",
    "contour_points = ar([[0,0,0],[LX,0,0],[LX,LY,0],[0,LY,0]])\n",
    "\n",
    "R0 = ar([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "x_, y_, z_ = R0[0], R0[1], R0[2]\n",
    "\n",
    "Frame1 = ar([z_,y_,-x_])\n",
    "Frame2 = ar([-z_,y_,x_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42692f0e-e845-4efa-9470-805dc0d65b3b",
   "metadata": {},
   "source": [
    "First we define the base part dictionaries for the upper and lower plate, without holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a1bb46-a7f6-4d9d-82f0-07ceccb9ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_data = {\n",
    "    \"PARTS\" : {\n",
    "        '0' : {\n",
    "            \"a\" : {\n",
    "                \"FRAME\": Frame1,\n",
    "                \"POINTS\": {'A0' : ar([0,0,0]),\n",
    "                           'A1' : ar([LX,0,0]),\n",
    "                           'A2' : ar([LX,LY,0]),\n",
    "                           'A3' : ar([0,LY,0]),\n",
    "                        },\n",
    "                \"TYPE\": \"plane\",\n",
    "                \"INTERACTIONS\": ['P1a'],\n",
    "                \"CONSTRAINTS_D\": [\"PERFECT\"],\n",
    "                \"CONSTRAINTS_G\": [\"SLIDING\"],            \n",
    "            }\n",
    "        },\n",
    "        '1' : {\n",
    "            \"a\" : {\n",
    "                \"FRAME\": Frame2,\n",
    "                \"POINTS\": {'A0' : ar([0,0,0]),\n",
    "                           'A1' : ar([LX,0,0]),\n",
    "                           'A2' : ar([LX,LY,0]),\n",
    "                           'A3' : ar([0,LY,0]),\n",
    "                        },\n",
    "                \"TYPE\": \"plane\",\n",
    "                \"INTERACTIONS\": ['P0a'],\n",
    "                \"CONSTRAINTS_D\": [\"PERFECT\"],\n",
    "                \"CONSTRAINTS_G\": [\"SLIDING\"],            \n",
    "            }\n",
    "        }  \n",
    "    },\n",
    "    \"LOOPS\": {\n",
    "        \"COMPATIBILITY\": {\n",
    "        },\n",
    "    },\n",
    "    \"GLOBAL_CONSTRAINTS\": \"3D\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e81a47-6214-4774-ab58-8d16bd43ac9b",
   "metadata": {},
   "source": [
    "Then we iterate over the pin dimensions NX and NY, and create the corresponding holes and pins. At the same time there is 1 loop per pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29491ebe-37b5-4879-a740-64db3434d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_gen = otaf.common.alphabet_generator()\n",
    "next(alpha_gen) # skipping 'a' as it has already been used above\n",
    "part_id = 2 # Start part index for pins\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        pcor = ar([LB+i*EH, LB+j*EH, 0]) # Point coordinate for hole / pins\n",
    "        slab = next(alpha_gen) # Surface label, same for each mating pin so its easeir to track\n",
    "        # Creating pin\n",
    "        system_data[\"PARTS\"][str(part_id)] = {}\n",
    "        system_data[\"PARTS\"][str(part_id)][slab] = {\n",
    "            \"FRAME\": Frame1, # Frame doesn't really matter, as long as x is aligned on the axis\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dint / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P0{slab}\", f\"P1{slab}\"], \n",
    "            \"SURFACE_DIRECTION\": \"centrifugal\",\n",
    "            \"CONSTRAINTS_D\": [\"PERFECT\"], # No defects on the pins\n",
    "            \"BLOCK_ROTATIONS_G\": 'x', # The pins do not rotate around their axis\n",
    "            \"BLOCK_TRANSLATIONS_G\": 'x', # The pins do not slide along their axis\n",
    "        }\n",
    "        # Adding hole to part 0\n",
    "        system_data[\"PARTS\"][\"0\"][slab] = {\n",
    "            \"FRAME\": Frame1,\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dext / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P{part_id}{slab}\"], \n",
    "            \"SURFACE_DIRECTION\": \"centripetal\",\n",
    "        }\n",
    "        # Adding hole to part 1\n",
    "        system_data[\"PARTS\"][\"1\"][slab] = {\n",
    "            \"FRAME\": Frame2,\n",
    "            \"ORIGIN\": pcor, \n",
    "            \"TYPE\": \"cylinder\",\n",
    "            \"RADIUS\": Dext / 2,\n",
    "            \"EXTENT_LOCAL\": {\"x_max\": hPin/2, \"x_min\": -hPin/2},\n",
    "            \"INTERACTIONS\": [f\"P{part_id}{slab}\"],\n",
    "            \"SURFACE_DIRECTION\": \"centripetal\",\n",
    "        }\n",
    "        # Construct Compatibility loop\n",
    "        loop_id = f\"L{part_id-1}\"\n",
    "        formater = lambda i,l : f\"P{i}{l}{l.upper()}0\" \n",
    "        system_data[\"LOOPS\"][\"COMPATIBILITY\"][loop_id] = f\"P0aA0 -> {formater(0,slab)} -> {formater(part_id,slab)} -> {formater(1,slab)} -> P1aA0\"\n",
    "        part_id += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293f981a-efe3-4b44-b9f3-b7a580cf3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDA = otaf.AssemblyDataProcessor(system_data)\n",
    "SDA.generate_expanded_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e26ae8-3e27-496d-ac65-9f4385d89105",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLH = otaf.CompatibilityLoopHandling(SDA)\n",
    "compatibility_expressions = CLH.get_compatibility_expression_from_FO_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87736588-7cec-4360-b748-2dfc7666461e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing part 0, surface b for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'b', 'B0', '2', 'b', 'B0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'b', 'B2', '2', 'b', 'B2'], ['0', 'b', 'B1', '2', 'b', 'B1']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0bB0P2bB0 with GP0bB2P2bB2\n",
      "Matching used and unused gap matrices: GP0bB0P2bB0 with GP0bB1P2bB1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 0, surface c for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'c', 'C0', '3', 'c', 'C0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'c', 'C2', '3', 'c', 'C2'], ['0', 'c', 'C1', '3', 'c', 'C1']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0cC0P3cC0 with GP0cC2P3cC2\n",
      "Matching used and unused gap matrices: GP0cC0P3cC0 with GP0cC1P3cC1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 0, surface d for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'd', 'D0', '4', 'd', 'D0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'd', 'D1', '4', 'd', 'D1'], ['0', 'd', 'D2', '4', 'd', 'D2']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0dD0P4dD0 with GP0dD1P4dD1\n",
      "Matching used and unused gap matrices: GP0dD0P4dD0 with GP0dD2P4dD2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 0, surface e for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['0', 'e', 'E0', '5', 'e', 'E0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['0', 'e', 'E1', '5', 'e', 'E1'], ['0', 'e', 'E2', '5', 'e', 'E2']]\n",
      "Found 2 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP0eE0P5eE0 with GP0eE1P5eE1\n",
      "Matching used and unused gap matrices: GP0eE0P5eE0 with GP0eE2P5eE2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 1, surface a for plane-to-plane interactions.\n",
      "usedGMatDat [['1', 'a', 'A0', '0', 'a', 'A0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['1', 'a', 'A3', '0', 'a', 'A3'], ['1', 'a', 'A2', '0', 'a', 'A2'], ['1', 'a', 'A1', '0', 'a', 'A1']]\n",
      "Found 3 unused gap matrices.\n",
      "Generated 3 interaction matrix loops for current matching.\n",
      "Processing part 2, surface b for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['2', 'b', 'B0', '1', 'b', 'B0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['2', 'b', 'B0', '0', 'b', 'B0'], ['2', 'b', 'B1', '1', 'b', 'B2'], ['2', 'b', 'B2', '1', 'b', 'B1'], ['2', 'b', 'B2', '0', 'b', 'B2'], ['2', 'b', 'B1', '0', 'b', 'B1']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP2bB0P1bB0 with GP2bB1P1bB2\n",
      "Matching used and unused gap matrices: GP2bB0P1bB0 with GP2bB2P1bB1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 3, surface c for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['3', 'c', 'C0', '1', 'c', 'C0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['3', 'c', 'C0', '0', 'c', 'C0'], ['3', 'c', 'C1', '1', 'c', 'C2'], ['3', 'c', 'C2', '0', 'c', 'C2'], ['3', 'c', 'C1', '0', 'c', 'C1'], ['3', 'c', 'C2', '1', 'c', 'C1']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP3cC0P1cC0 with GP3cC1P1cC2\n",
      "Matching used and unused gap matrices: GP3cC0P1cC0 with GP3cC2P1cC1\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 4, surface d for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['4', 'd', 'D0', '1', 'd', 'D0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['4', 'd', 'D2', '1', 'd', 'D1'], ['4', 'd', 'D1', '0', 'd', 'D1'], ['4', 'd', 'D1', '1', 'd', 'D2'], ['4', 'd', 'D2', '0', 'd', 'D2'], ['4', 'd', 'D0', '0', 'd', 'D0']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP4dD0P1dD0 with GP4dD2P1dD1\n",
      "Matching used and unused gap matrices: GP4dD0P1dD0 with GP4dD1P1dD2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n",
      "Processing part 5, surface e for cylinder-to-cylinder interactions.\n",
      "usedGMatDat [['5', 'e', 'E0', '1', 'e', 'E0']]\n",
      "Found 1 used gap matrices.\n",
      "unusedGMatDat [['5', 'e', 'E2', '1', 'e', 'E1'], ['5', 'e', 'E1', '0', 'e', 'E1'], ['5', 'e', 'E1', '1', 'e', 'E2'], ['5', 'e', 'E2', '0', 'e', 'E2'], ['5', 'e', 'E0', '0', 'e', 'E0']]\n",
      "Found 5 unused gap matrices.\n",
      "Matching used and unused gap matrices: GP5eE0P1eE0 with GP5eE2P1eE1\n",
      "Matching used and unused gap matrices: GP5eE0P1eE0 with GP5eE1P1eE2\n",
      "Generated 32 interaction equations for current matching.\n",
      "Total interaction equations generated: 32\n"
     ]
    }
   ],
   "source": [
    "ILH = otaf.InterfaceLoopHandling(SDA, CLH, circle_resolution=CIRCLE_RESOLUTION)\n",
    "interface_constraints = ILH.get_interface_loop_expressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d2f4ba-f4bd-425a-ba0c-50cabc500272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [v_d_0, w_d_0, beta_d_0, gamma_d_0, v_d_2, w_d_2, beta_d_2, gamma_d_2, v_d_5, w_d_5, beta_d_5, gamma_d_5, v_d_7, w_d_7, beta_d_7, gamma_d_7, v_d_8, w_d_8, beta_d_8, gamma_d_8, v_d_10, w_d_10, beta_d_10, gamma_d_10, v_d_11, w_d_11, beta_d_11, gamma_d_11, v_d_13, w_d_13, beta_d_13, gamma_d_13]\n"
     ]
    }
   ],
   "source": [
    "SOCAM = otaf.SystemOfConstraintsAssemblyModel(\n",
    "    compatibility_expressions, interface_constraints\n",
    ")\n",
    "\n",
    "SOCAM.embedOptimizationVariable()\n",
    "\n",
    "print(len(SOCAM.deviation_symbols), SOCAM.deviation_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be834b-fc7d-4fc3-85eb-2d8768c446ed",
   "metadata": {},
   "source": [
    "## Construction of the stochastic model of the defects.\n",
    "\n",
    "These are the max variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31049a41-8b2a-49c0-8142-2819f94c51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.1 * np.sqrt(2)\n",
    "Cm = 1  # Process capability\n",
    "\n",
    "# Defining the uncertainties on the position and orientation uncertainties.\n",
    "sigma_e_pos = tol / (6 * Cm)\n",
    "theta_max = tol / hPlate\n",
    "sigma_e_theta = (2 * theta_max) / (6 * Cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449f3658-2055-4cd6-a9bb-0ef7d520204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandDeviationVect = otaf.distribution.get_composed_normal_defect_distribution(\n",
    "    defect_names=SOCAM.deviation_symbols,\n",
    "    sigma_dict = {\"alpha\":sigma_e_theta, \n",
    "                  \"beta\":sigma_e_theta,\n",
    "                  \"gamma\":sigma_e_theta, \n",
    "                  \"u\":sigma_e_pos, \n",
    "                  \"v\":sigma_e_pos, \n",
    "                  \"w\":sigma_e_pos})\n",
    "dim_devs = int(RandDeviationVect.getDimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d99d7-56c6-4b9f-a4de-d28268b35398",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSTOP\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a0a59-111e-461e-b796-afacf7adce72",
   "metadata": {},
   "source": [
    "## Estimating the bounds on the probability of failure of the model.\n",
    "\n",
    "- First by exploring the whle parameter space, by generating a LHS in the (normalized) parameter space and doing a double loop montecarlo\n",
    "- By using the parameter constraint function to guide an optimization algorithm to find the bounds on the probability of failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b207f-7a0c-4bdd-96d3-12d235ee3202",
   "metadata": {},
   "source": [
    "## Now lets first to a double loop monte-carlo to explore the full space of the parameters (using the intermediate lambda space) and the stochastic space, to be able to draw the full P-Box of the slack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60040ec1-5d78-428e-ba44-6b6adb01de5f",
   "metadata": {},
   "source": [
    "### Explicit constraint function on the 4 degrees of freedom of the cylindrical tolerance zone :\n",
    "\n",
    "$$λu2​+λv2​+λα2​+λβ2​+2(λu​λα​+λv​λβ​)−1=0$$\n",
    "\n",
    "This the constraint on the multipliers of the max standard deviation for each component of the DOFs. The defects are normal, centered and independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc29a0a-6b65-47e8-9c0d-6ce3ca604abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_limit_sample = otaf.sampling.generate_imprecise_probabilistic_samples([4]*8, -1, discretization=1)\n",
    "lambda_limit_sample_sub_choice = [next(lambda_limit_sample) for _ in range(60000)]\n",
    "lambda_limit_sample_sub_choice = np.stack(lambda_limit_sample_sub_choice)\n",
    "print(lambda_limit_sample_sub_choice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a0477-968f-4b75-8450-316b000245cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_lambda_beta(lambda_u, lambda_v, lambda_alpha):\n",
    "    \"\"\"\n",
    "    Solve the equation for lambda_beta given lambda_u, lambda_v, and lambda_alpha.\n",
    "    \"\"\"\n",
    "    def equation(lambda_beta):\n",
    "        return (lambda_u**2 + lambda_v**2 + lambda_alpha**2 + lambda_beta**2 +\n",
    "                2 * (lambda_u * lambda_alpha + lambda_v * lambda_beta) - 1)\n",
    "    \n",
    "    # Use a root-finding method to solve for lambda_beta\n",
    "    lambda_beta_initial_guess = 0.5\n",
    "    lambda_beta_solution = fsolve(equation, lambda_beta_initial_guess)[0]\n",
    "    \n",
    "    return lambda_beta_solution\n",
    "\n",
    "def generate_points_on_surface(num_points=1000):\n",
    "    \"\"\"\n",
    "    Generate points on the surface by solving for lambda_beta\n",
    "    given random values for lambda_u, lambda_v, and lambda_alpha.\n",
    "    \n",
    "    Returns:\n",
    "    - A numpy array of shape (num_valid_points, 4) where each row is \n",
    "      (lambda_u, lambda_v, lambda_alpha, lambda_beta).\n",
    "    \"\"\"\n",
    "    # Generate random values for lambda_u, lambda_v, lambda_alpha in [0, 1]\n",
    "    lambda_u = np.random.rand(num_points)\n",
    "    lambda_v = np.random.rand(num_points)\n",
    "    lambda_alpha = np.random.rand(num_points)\n",
    "    \n",
    "    # Assume lambda_beta = 0 and check if the inequality is satisfied\n",
    "    inequality_values = lambda_u**2 + lambda_v**2 + lambda_alpha**2 + 2 * (lambda_u * lambda_alpha)\n",
    "\n",
    "    # Filter valid points where inequality holds\n",
    "    valid_mask = inequality_values <= 1\n",
    "    lambda_u_valid = lambda_u[valid_mask]\n",
    "    lambda_v_valid = lambda_v[valid_mask]\n",
    "    lambda_alpha_valid = lambda_alpha[valid_mask]\n",
    "    \n",
    "    # Solve for lambda_beta for valid points\n",
    "    lambda_beta_valid = np.array([solve_for_lambda_beta(u, v, a) \n",
    "                                  for u, v, a in zip(lambda_u_valid, lambda_v_valid, lambda_alpha_valid)])\n",
    "\n",
    "    # Only keep points where the solved lambda_beta is between 0 and 1\n",
    "    final_mask = (lambda_beta_valid >= 0) & (lambda_beta_valid <= 1)\n",
    "    final_points = np.vstack((lambda_u_valid[final_mask],\n",
    "                              lambda_v_valid[final_mask],\n",
    "                              lambda_alpha_valid[final_mask],\n",
    "                              lambda_beta_valid[final_mask])).T\n",
    "    \n",
    "    return final_points\n",
    "\n",
    "# Generate the points on the surface\n",
    "points = generate_points_on_surface(num_points=20000)\n",
    "\n",
    "# Call the pair_plot function (assuming it's already defined)\n",
    "labels = ['lambda_u', 'lambda_v', 'lambda_alpha', 'lambda_beta']\n",
    "#otaf.plotting.pair_plot(points, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec9b31-167f-41ab-a3d2-38000577a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_lambda_sample = [points[np.random.choice(points.shape[0], 200, replace=False)] for _ in range(8)]\n",
    "random_lambda_sample = np.hstack(random_lambda_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a858d-1a85-48cd-841e-205c10da8e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_lambda = random_lambda_sample.shape[0]\n",
    "bounds = None\n",
    "SEED_MC_PF = 6436431\n",
    "SIZE_MC_PF = 10000 #int(1e6) #1e4\n",
    "s_values = np.zeros((N_lambda, SIZE_MC_PF)) # For each MC point we have a s value\n",
    "GLD_parameters = [] # We need the parameters of the generalized lambda distribution.\n",
    "failure_probabilities = []\n",
    "# Generalized lambda distribution object for fitting\n",
    "gld = GLD('VSL')\n",
    "\n",
    "start_time = time()  # Record the start time\n",
    "for i in range(N_lambda):\n",
    "    print(f\"Doing iteration {i} of {N_lambda}\")\n",
    "    if i>0:\n",
    "        fp = failure_probabilities\n",
    "        print(f\"Failure probability i-1 : {fp[i-1]}, Min: {min(fp)}, / Max: {max(fp)}\")\n",
    "        print(\"s_mean: \", s_values.mean().round(3), \"s_min: \", np.nanmin(s_values).round(3), \"s_max: \", np.nanmax(s_values).round(3))\n",
    "\n",
    "    ot.RandomGenerator.SetSeed(SEED_MC_PF)\n",
    "    deviation_samples = np.array(RandDeviationVect.getSample(SIZE_MC_PF)) * random_lambda_sample[i]\n",
    "    optimizations = otaf.uncertainty.compute_gap_optimizations_on_sample(\n",
    "            SOCAM,\n",
    "            deviation_samples,\n",
    "            bounds=bounds,\n",
    "            n_cpu=-1,\n",
    "            progress_bar=True,\n",
    "        )\n",
    "    \n",
    "    slack = np.array([opt.fun for opt in optimizations], dtype=float)*-1 #Normally there aren\"t any nans.\n",
    "    s_values[i,:] = slack\n",
    "    GLD_parameters.append(gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False))\n",
    "    failure_probabilities.append(gld.CDF_num(0, GLD_parameters[i]))\n",
    "\n",
    "\n",
    "print(f\"Done {N_lambda} experiments.\")\n",
    "print(f\"Elapsed time: {time() - start_time:.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba797e-b00f-4523-8476-b97e5b4c132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = otaf.sampling.find_best_worst_quantile(np.array(random_lambda_sample), np.array(failure_probabilities), 0.1)\n",
    "(best_5p_lambda, best_5p_res), (worst_5p_lambda, worst_5p_res) = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d1b15-9131-4741-a4cb-b4217637c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = [ot.UserDefined(ot.Sample(s[:,np.newaxis])) for s in s_values]\n",
    "x_min, x_max = -0.03, 0.11\n",
    "sup_data, inf_data = otaf.distribution.compute_sup_inf_distributions(distributions, x_min, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527d338-2d2b-43c0-9e76-8e03c57d6240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f384b-26ca-4aa0-8ec1-1471f2884d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize colors and legends for each lambda sample\n",
    "colors = [[\"grey\"]] * N_lambda\n",
    "legends = [\"\"] * N_lambda\n",
    "\n",
    "# Plot the combined CDF with additional curves for the envelopes\n",
    "graph_full = otaf.plotting.plot_combined_CDF(distributions, x_min, x_max, colors, legends)\n",
    "graph_full = otaf.plotting.set_graph_legends(\n",
    "    graph_full,\n",
    "    x_title=\"slack\",\n",
    "    y_title=\"$P_{slack}$\",\n",
    "    title=\"Slack P-BOX 32 dimensions\",\n",
    "    legends=legends\n",
    ")\n",
    "\n",
    "# Add the upper and lower envelopes to the graph\n",
    "graph_full.add(ot.Curve(inf_data, \"blue\", \"solid\", 1.5, \"lower envelope\"))\n",
    "graph_full.add(ot.Curve(sup_data, \"red\", \"solid\", 1.5, \"upper envelope\"))\n",
    "view = viewer.View(graph_full, pixelsize=(1100, 750))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9723baf-f91d-4ce9-ad5b-7fcfd88c1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "fig = plt.figure(dpi=150)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(sup_data[:, 0], sup_data[:, 1], color=\"tab:orange\", label=\"upper envelope\")\n",
    "ax.plot(inf_data[:, 0], inf_data[:, 1], color=\"tab:blue\", label=\"lower envelope\")\n",
    "ax.grid(True)\n",
    "ax.fill_between(\n",
    "    inf_data[:, 0], inf_data[:, 1], sup_data[:, 1], color=\"gray\", alpha=0.3\n",
    ")\n",
    "ax.set_xlabel(\"slack\")\n",
    "ax.set_ylabel(\"$P_{slack}$\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Slack P-Box 3D Assembly 32D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176e60a-1b48-467c-bbd8-a654452c511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum failure probability: {np.min(failure_probabilities):.5e}, Maximum failure probability: {np.max(failure_probabilities):.5e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f9521-d4fd-483e-a4da-bb5617225b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab91c6-d998-41d1-8739-502140b07ef4",
   "metadata": {},
   "source": [
    "## Global optimization basinhopping with GLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b659ba-59be-4385-a1a4-d2b2aebc6f5f",
   "metadata": {},
   "source": [
    "### First we define the optimization functions $P_f(\\Theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b3fbdc-2bc3-4e79-a1b3-2dacfa491e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_MC_PF = 10000 #int(1e6) #1e4\n",
    "sample_gld = otaf.sampling.generate_and_transform_sequence(RandDeviationVect.getDimension(), SIZE_MC_PF, RandDeviationVect) \n",
    "# np.array(RandDeviationVect.getSample(SIZE_MC_PF))\n",
    "scale_factor = 1.0\n",
    "GLD_parameters = [] # We need the parameters of the generalized lambda distribution.\n",
    "\n",
    "result_list = [] # Will be list of lists, where each sub list is a list of the input vector x and one for the gld paramters\n",
    "\n",
    "# Generalized lambda distribution object for fitting\n",
    "gld = GLD('VSL')\n",
    "\n",
    "def model_base(x, sample=sample_gld):\n",
    "    # Model without surrogate, to get slack\n",
    "    x = sample * np.sqrt(x[np.newaxis, :])\n",
    "    optimization_variables = otaf.uncertainty.compute_gap_optimizations_on_sample_batch(\n",
    "        constraint_matrix_generator=SOCAM,\n",
    "        deviation_array=x,\n",
    "        batch_size=500,\n",
    "        n_cpu=-1,\n",
    "        progress_bar=True,\n",
    "        verbose=0,\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    slack_values = optimization_variables[:,-1]\n",
    "    return slack_values\n",
    "\n",
    "@otaf.optimization.scaling(scale_factor)\n",
    "def optimization_function_mini(x, model=model_base):\n",
    "    # Here we search the minimal probability of failure\n",
    "    slack = model(x)\n",
    "    gld_params = gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False)\n",
    "    if np.any(np.isnan(gld_params)):\n",
    "        failure_probability = np.where(slack<0,1,0).mean()\n",
    "    else :\n",
    "        print(\"gld_params:\", gld_params)\n",
    "        failure_probability = gld.CDF_num(0, gld_params)\n",
    "    return failure_probability\n",
    "\n",
    "@otaf.optimization.scaling(scale_factor)\n",
    "def optimization_function_maxi(x, model=model_base):\n",
    "    # Here we search the maximal probability of failure so negative output\n",
    "    slack = model(x)\n",
    "    gld_params = gld.fit_LMM(slack, disp_fit=False, disp_optimizer=False)\n",
    "    if np.any(np.isnan(gld_params)):\n",
    "        failure_probability = np.where(slack<0,1,0).mean()\n",
    "    else :\n",
    "        print(\"gld_params:\", gld_params)\n",
    "        failure_probability = gld.CDF_num(0, gld_params)\n",
    "    return failure_probability*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805656b-91b6-4e12-bd5b-a8f2b984eea6",
   "metadata": {},
   "source": [
    "### Variance (std) based parameter constraint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5ac89-cf9f-44bc-a7bb-7628704e4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "midof_funcs = otaf.tolerances.MiSdofToleranceZones()\n",
    "\n",
    "feature_constraint_list = []\n",
    "\n",
    "# We know that all features are cylindrical, with same values/dimensions\n",
    "for i in range(8):\n",
    "    fconst = otaf.tolerances.FeatureLevelStatisticalConstraint(\n",
    "        midof_funcs.cylindrical_zone,\n",
    "        mif_args = (tol, hPlate),\n",
    "        n_dof = 4,\n",
    "        n_sample = 30000,\n",
    "        target = \"std\", #\"prob\",\n",
    "        target_val = sigma_e_pos*np.sqrt(1-(2/np.pi)), #0.002699, #\n",
    "        isNormal = True,\n",
    "        normalizeOutput = True,\n",
    "    )\n",
    "    feature_constraint_list.append(fconst)\n",
    "\n",
    "# The input of this object would be a list of parameters (their real value)\n",
    "composed_assembly_constraint = otaf.tolerances.ComposedAssemblyLevelStatisticalConstraint(feature_constraint_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c2424-bc79-4379-bc24-6ca62a8a1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds_one_feature = [[0.0,0.0], [1e-8, sigma_e_pos], #u, mean std\n",
    "                            [0.0,0.0], [1e-8, sigma_e_pos], #v, mean std\n",
    "                            [0.0,0.0], [1e-8, sigma_e_theta], #alpha, mean std\n",
    "                            [0.0,0.0], [1e-8, sigma_e_theta] # beta, mean std\n",
    "                           ]\n",
    "param_bounds = [param_bounds_one_feature] * 8 #We have 8 identical features\n",
    "\n",
    "# The input of this object is a list of normalized parameters (between 0 and 1)\n",
    "normalized_assembly_constraint = otaf.tolerances.NormalizedAssemblyLevelConstraint(\n",
    "    composed_assembly_constraint,\n",
    "    param_val_bounds=param_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836b5ec-5be9-4f70-a69a-4a8e88ea6714",
   "metadata": {},
   "source": [
    "#### The assembly constraint takes as an input the list of list of paramters for all the features. But as the distriutions (normals) are suppposed to be centered, we only need to have the standard deviations as inputs so we construct a little intermediary class that takes as an input only the standard deviations and not the means, and completes the means with 0 to pass it to the assembly constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e9f22-18a2-45b1-8385-bd611fc3b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assembly_constraint_no_mean(param_list, scale_out=True):\n",
    "    \"\"\" The functions takes directly the concatenated list of all normalized parameters, and reconstructs the right object.\n",
    "    There should be 32 variables for the standard deviations, we just add the mean values in the vector so the input is correct \n",
    "    for the constraint object\n",
    "    \"\"\"\n",
    "    assert len(param_list)==32, \"problem with input.\"\n",
    "    zer = np.zeros(4) # These are the mean values (all 0)\n",
    "    pl = np.array(param_list)\n",
    "    params_for_assembly = []\n",
    "    for i in range(8):\n",
    "        params = param_list[i*4:i*4+4]\n",
    "        pa = [item for pair in zip(zer, params) for item in pair]\n",
    "        params_for_assembly.append(pa)\n",
    "    res =  normalized_assembly_constraint(params_for_assembly)\n",
    "    if scale_out :\n",
    "        return res * 10\n",
    "    else :\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23affa0b-94cd-48f7-9c4f-b19222032e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_assembly_constraint_no_mean = lambda x : approx_fprime(x, \n",
    "              assembly_constraint_no_mean,\n",
    "              0.001, \n",
    "              True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa290c-0362-4a63-83cb-d154d98b52f2",
   "metadata": {},
   "source": [
    "#### Now we create the assembly constraint for the optimization (so a non linear constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38aadcb-2449-4f63-848a-8e040c286905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nonlinear constraint with the updated vector-valued function and Jacobian\n",
    "nonLinearConstraint = NonlinearConstraint(\n",
    "    fun=assembly_constraint_no_mean,\n",
    "    lb = -0.001 * np.ones((8,)), # Maybe could be directly 0\n",
    "    ub = 0.001 * np.ones((8,)),\n",
    "    #jac = jac_assembly_constraint_no_mean, #jac doesn't work for COBYQA\n",
    "    keep_feasible=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab850de-58dc-409c-9ee7-43f2255455da",
   "metadata": {},
   "source": [
    "#### Optimization to find the maximal probability of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b9a4c-a5b7-4f29-add9-b0e2bfaac476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial guess\n",
    "x0_maxi = [0.5] * RandDeviationVect.getDimension()  # Initial guess\n",
    "\n",
    "# Perform the local optimization using COBYQA directly\n",
    "res_maxi = minimize(\n",
    "    optimization_function_maxi, \n",
    "    x0_maxi, \n",
    "    method=\"COBYQA\", \n",
    "    jac=None, \n",
    "    bounds=Bounds(0.0, 1.0, keep_feasible=True),\n",
    "    constraints = nonLinearConstraint,\n",
    "    options={\n",
    "        \"f_target\": -0.1, \n",
    "        \"maxiter\": 1000,\n",
    "        \"maxfev\": 4000,\n",
    "        \"feasibility_tol\": 1e-9,\n",
    "        \"initial_tr_radius\": np.sqrt(2*32),\n",
    "        \"final_tr_radius\": 1e-6,\n",
    "        \"disp\": True,\n",
    "        \"scale\": False #True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Maximization Result with COBYQA:\")\n",
    "print(res_maxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407fdfa-f80d-46ae-9a47-36c7d99c61df",
   "metadata": {},
   "source": [
    "#### Optimization to find the minimal probability of failure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd6dbb-f38e-4034-97f8-1caabfb44a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial guess\n",
    "x0_mini = [0.5] * RandDeviationVect.getDimension()  # Initial guess\n",
    "\n",
    "# Perform the local optimization using COBYQA directly\n",
    "res_mini = minimize(\n",
    "    optimization_function_mini, \n",
    "    x0_mini, \n",
    "    method=\"COBYQA\", \n",
    "    jac=None, \n",
    "    bounds=Bounds(0.0, 1.0, keep_feasible=True),\n",
    "    constraints = nonLinearConstraint,\n",
    "    options={\n",
    "        \"f_target\": -0.01, #Has to be  \n",
    "        \"maxiter\": 1000,\n",
    "        \"maxfev\": 4000,\n",
    "        \"feasibility_tol\": 1e-9,\n",
    "        \"initial_tr_radius\": np.sqrt(2*32),\n",
    "        \"final_tr_radius\": 1e-6,\n",
    "        \"disp\": True,\n",
    "        \"scale\": False #True\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"minimization Result with COBYQA:\")\n",
    "print(res_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b32bf3-1f8a-4e76-8cf0-e8df3e45090d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b0eb93f-1a5a-456a-ad65-b86f0c100471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(python:34792): Gtk-WARNING **: 18:51:55.725: Could not load a pixbuf from icon theme.\n",
      "This may indicate that pixbuf loaders or the mime database could not be found.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "otaf.plotting.plot_gld_pbox_cdf(gld,\n",
    "          [0.05388563, 0.01424974, 0.39190849, 0.12699835], \n",
    "          [0.04306886, 0.02397462, 0.36453265, 0.13973758],\n",
    "          np.linspace(-0.025, 0.085, 1000),\n",
    "          xlabel=\"s\", ylabel=r\"$P_f$\", title=\"P-Box of the Slack\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb5870-0875-4677-9efe-c2bee9e9f7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basinhopping for the maximization function using COBYQA\n",
    "x0_maxi = [0.25] * RandDeviationVect.getDimension()  # Initial guess\n",
    "\n",
    "# Update minimizer_kwargs_maxi to use COBYQA\n",
    "minimizer_kwargs_maxi = {\n",
    "    \"method\": \"COBYQA\",   # Use COBYQA method\n",
    "    \"args\": (model_base,),     # Update args to match COBYQA requirements\n",
    "    \"constraints\": nonLinearConstraint,\n",
    "    \"bounds\": Bounds(lb=0.0,ub=1.0, keep_feasible=True),\n",
    "    \"options\": {\n",
    "        \"f_target\": -0.1, \n",
    "        \"maxiter\": 1000,\n",
    "        \"maxfev\": 4000,\n",
    "        \"feasibility_tol\": 1e-9, # tol on constraint violation\n",
    "        \"initial_tr_radius\": np.sqrt(2*32),\n",
    "        \"final_tr_radius\": 1e-4,\n",
    "        \"disp\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Running basinhopping with COBYQA as the local optimizer\n",
    "res_maxi = basinhopping(\n",
    "    optimization_function_maxi, x0_maxi,\n",
    "    niter=5,\n",
    "    T=1,\n",
    "    stepsize=3.0,\n",
    "    niter_success=19,\n",
    "    interval=5,\n",
    "    minimizer_kwargs=minimizer_kwargs_maxi,\n",
    "    disp=True,\n",
    "    #take_step=step_taking,\n",
    "    #accept_test=accept_test,\n",
    "    #callback=callback\n",
    ")\n",
    "\n",
    "print(\"Maximization Result with COBYQA:\")\n",
    "print(res_maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3c1a4-7d8f-441d-a59d-6be0897b7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_maxi.x.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687ab1e-cb51-4d88-8aac-39655110c711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fea5b5-191c-4ee7-be87-e7cc47a123f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = ot.Normal()\n",
    "func = ot.SymbolicFunction([\"x\"], [\"abs(x)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd7a4a-8080-492e-bcd3-f818072e212e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
